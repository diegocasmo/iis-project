\section{Secondary Groups}

%TODO: Explain format read from the Computer Vision group (and results if we manage to get some examples of their work), and output given to the Emotion Synthesis group
Our Secondary groups were Computer Vision (CV) and Emotion Synthesis (ES). Our task in the final pipeline was to read the input given by CV group and send the output to ES group.

\subsection{Computer Vision Group}
%Format read from CV Group
After training our models with the Bosphorus Database we need to predict an emotion by reading input from the CV group. They are creating an array containing $25$ landmarks and passing it as input into our models. PCA was used for dimensionality reduction before training our model, so the same PCA model is used on the given input for reducing the number of features.

\subsection{Emotion Synthesis Group}
%Format given to Emotion Synthesis Group
We are using a SVM model trained on Bosphorus Dataset as it is more stable and gives better accuracy as seen in the Implementation section. We are sending output in a Python dictionary format which contatins all six labels with their confidence score. Confidence scores tells us about the probability of the emotion predicted by our model. % We are also sent a confusion matrix of our model so that they can get an idea of how well our model is performing for each of the labels.

%Reflection on how well the integration in the final pipeline worked
%what worked well
%what were challenges
\subsection{Challenges}
Each group worked on a different operating system, this was a huge problem when we met to integrate all our solutions. Having all our code in Python we were the most platform agnostic group and integrating our code in either direction (toward CV or ES) was trivial. What was impossible in the time we had was getting ES code to work on the CV groups computers and vice-versa. From the CV group, at first, they were not delivering the 25 landmarks in the same order, in less than 20 minutes of collaboration we were able to reorder the array they gave us ot the correct order. Despite this integration, their solution was not very accurate, landmarks --visualized as points overlayed on the live camera image-- were rarely on the face, so we could not truly observe our solution with real world data. With the ES group, they were using Python 2.7, we took about an hour to downgrade our code from Python 3.6. From there, we presume, there were no problems in integrating our code with the ES group's solutions.
