\section{Secondary Groups}

%TODO: Explain format read from the Computer Vision group (and results if we manage to get some examples of their work), and output given to the Emotion Synthesis group
Our Secondary groups were Computer Vision (CV) and Emotion Synthesis (ES). Our task in the final pipeline was to read the input given by CV group and send the output to ES group.

\subsection{Computer Vision Group}
%Format read from CV Group
After training our models we need to predict an emotion by reading input from the CV group. They are creating an array containing $25$ landmarks and passing it as input into our models. PCA was used for dimensionality reduction before training our model, so the same PCA model is used on the given input for reducing the number of features.

\subsection{Emotion Synthesis Group}
%Format given to Emotion Synthesis Group
We are using an SVM model as it is the most stable and gives the best accuracy as seen in the Results section. We are sending output in a Python dictionary format which contains all six labels with their confidence score. Confidence scores tells us about the probability of the emotion predicted by our model. % We are also sent a confusion matrix of our model so that they can get an idea of how well our model is performing for each of the labels.

%Reflection on how well the integration in the final pipeline worked
%what worked well
%what were challenges
\subsection{Challenges}
Each group worked on a different operating system, this was a huge problem when we met to integrate all of our solutions. Having written all of our code in Python, we were the most platform agnostic group and integrating our code in either direction (toward CV or ES) was trivial. What was quite difficult was getting ES code to work on the CV groups computers and vice-versa. From the CV group, at first, they were not delivering the 25 landmarks in the same order as we were expecting, in less than 20 minutes of collaboration we were able to correctly order the input. Despite this integration, their solution was not very accurate, landmarks --visualized as points overlayed on the live camera image-- were rarely on the face, so we could not truly observe our solution working with real world data. With the ES group, they were using Python 2.7, we took about an hour to downgrade our code from Python 3.6. From there, we presume, there were no problems in integrating our code with the ES group's solutions.
