\section{Results}

Each subsection here is dedicated to a method and is accompanied with two confusion matrices for \tsne and PCA each. The matrix is from a single run of the model. Results are otherwise measured by running the model 100 times on different random splits of data which has been preprocessed with PCA methods discussed in implementation. From these runs we can extract the average accuracy and standard deviation for each model and determine the best one.

\subsection{kNN}

\twoupfigure{pca-knn}{tsne-knn}{Confustion matrices for KNN.}{PCA}{\tsne}{knn-conf}

With KNN methods we can attain an average accuracy of $47.3\%$ with a standard deviation of $0.045$. This is less than mediocre.

\subsection{MLP}

\twoupfigure{pca-mlp}{tsne-mlp}{Confustion matrices for MLP.}{PCA}{\tsne}{mlp-conf}

With MLP methods we can attain an accuracy of $73.3\%$ with a standard deviation of $0.037$. This is great.

\subsection{Random Forests}

\twoupfigure{pca-rf}{tsne-rf}{Confustion matrices for RF.}{PCA}{\tsne}{rf-conf}

With RF methods we can attain an accuracy of $62.9\%$ with a standard deviation of $0.040$. While consistent, it is still about 10\% less accurate than the competing supervised methods.

\subsection{SVM}

\twoupfigure{pca-svm}{tsne-svm}{Confustion matrices for SVM.}{PCA}{\tsne}{svm-conf}

With SVM methods we get an accuracy of $74.00\%$ with a standard deviation of $0.039$. At a marginal detriment to consistency, this makes it the most accurate model we tried.