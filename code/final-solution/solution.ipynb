{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Classification of The Bosphorus Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Short description of dataset and the goal of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe data pre-processing steps to create the ``.csv`` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_df = pd.read_csv(r'../../data/lm3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Dataset Format and Number of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: description of the dataset format (i.e. each column represents a label in a particular dimension...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: \t79\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Outer left eyebrow-x</th>\n",
       "      <th>Outer left eyebrow-y</th>\n",
       "      <th>Outer left eyebrow-z</th>\n",
       "      <th>Middle left eyebrow-x</th>\n",
       "      <th>Middle left eyebrow-y</th>\n",
       "      <th>Middle left eyebrow-z</th>\n",
       "      <th>Inner left eyebrow-x</th>\n",
       "      <th>Inner left eyebrow-y</th>\n",
       "      <th>Inner left eyebrow-z</th>\n",
       "      <th>...</th>\n",
       "      <th>Lower lip outer middle-z</th>\n",
       "      <th>Chin middle-x</th>\n",
       "      <th>Chin middle-y</th>\n",
       "      <th>Chin middle-z</th>\n",
       "      <th>Left ear lobe-x</th>\n",
       "      <th>Left ear lobe-y</th>\n",
       "      <th>Left ear lobe-z</th>\n",
       "      <th>Right ear lobe-x</th>\n",
       "      <th>Right ear lobe-y</th>\n",
       "      <th>Right ear lobe-z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANGER</td>\n",
       "      <td>-72.961</td>\n",
       "      <td>-1.725</td>\n",
       "      <td>22.958</td>\n",
       "      <td>-55.678</td>\n",
       "      <td>4.591</td>\n",
       "      <td>38.791</td>\n",
       "      <td>-31.920</td>\n",
       "      <td>-1.929</td>\n",
       "      <td>36.645</td>\n",
       "      <td>...</td>\n",
       "      <td>39.421</td>\n",
       "      <td>-9.840</td>\n",
       "      <td>-112.234</td>\n",
       "      <td>31.313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DISGUST</td>\n",
       "      <td>-76.565</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>6.126</td>\n",
       "      <td>-62.086</td>\n",
       "      <td>9.454</td>\n",
       "      <td>24.055</td>\n",
       "      <td>-35.614</td>\n",
       "      <td>2.066</td>\n",
       "      <td>25.073</td>\n",
       "      <td>...</td>\n",
       "      <td>24.378</td>\n",
       "      <td>-13.583</td>\n",
       "      <td>-109.568</td>\n",
       "      <td>19.583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FEAR</td>\n",
       "      <td>-76.163</td>\n",
       "      <td>6.390</td>\n",
       "      <td>10.784</td>\n",
       "      <td>-57.083</td>\n",
       "      <td>16.865</td>\n",
       "      <td>30.162</td>\n",
       "      <td>-33.708</td>\n",
       "      <td>14.082</td>\n",
       "      <td>32.408</td>\n",
       "      <td>...</td>\n",
       "      <td>42.100</td>\n",
       "      <td>-13.020</td>\n",
       "      <td>-110.107</td>\n",
       "      <td>33.429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAPPY</td>\n",
       "      <td>-72.140</td>\n",
       "      <td>8.896</td>\n",
       "      <td>9.353</td>\n",
       "      <td>-54.721</td>\n",
       "      <td>22.380</td>\n",
       "      <td>27.474</td>\n",
       "      <td>-29.789</td>\n",
       "      <td>15.802</td>\n",
       "      <td>28.937</td>\n",
       "      <td>...</td>\n",
       "      <td>38.018</td>\n",
       "      <td>-9.030</td>\n",
       "      <td>-97.687</td>\n",
       "      <td>36.058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SADNESS</td>\n",
       "      <td>-73.743</td>\n",
       "      <td>3.099</td>\n",
       "      <td>12.438</td>\n",
       "      <td>-58.607</td>\n",
       "      <td>15.144</td>\n",
       "      <td>29.381</td>\n",
       "      <td>-32.979</td>\n",
       "      <td>11.594</td>\n",
       "      <td>30.048</td>\n",
       "      <td>...</td>\n",
       "      <td>41.452</td>\n",
       "      <td>-10.731</td>\n",
       "      <td>-100.452</td>\n",
       "      <td>35.956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label  Outer left eyebrow-x  Outer left eyebrow-y  Outer left eyebrow-z  \\\n",
       "0    ANGER               -72.961                -1.725                22.958   \n",
       "1  DISGUST               -76.565                -0.458                 6.126   \n",
       "2     FEAR               -76.163                 6.390                10.784   \n",
       "3    HAPPY               -72.140                 8.896                 9.353   \n",
       "4  SADNESS               -73.743                 3.099                12.438   \n",
       "\n",
       "   Middle left eyebrow-x  Middle left eyebrow-y  Middle left eyebrow-z  \\\n",
       "0                -55.678                  4.591                 38.791   \n",
       "1                -62.086                  9.454                 24.055   \n",
       "2                -57.083                 16.865                 30.162   \n",
       "3                -54.721                 22.380                 27.474   \n",
       "4                -58.607                 15.144                 29.381   \n",
       "\n",
       "   Inner left eyebrow-x  Inner left eyebrow-y  Inner left eyebrow-z  \\\n",
       "0               -31.920                -1.929                36.645   \n",
       "1               -35.614                 2.066                25.073   \n",
       "2               -33.708                14.082                32.408   \n",
       "3               -29.789                15.802                28.937   \n",
       "4               -32.979                11.594                30.048   \n",
       "\n",
       "         ...         Lower lip outer middle-z  Chin middle-x  Chin middle-y  \\\n",
       "0        ...                           39.421         -9.840       -112.234   \n",
       "1        ...                           24.378        -13.583       -109.568   \n",
       "2        ...                           42.100        -13.020       -110.107   \n",
       "3        ...                           38.018         -9.030        -97.687   \n",
       "4        ...                           41.452        -10.731       -100.452   \n",
       "\n",
       "   Chin middle-z  Left ear lobe-x  Left ear lobe-y  Left ear lobe-z  \\\n",
       "0         31.313              NaN              NaN              NaN   \n",
       "1         19.583              NaN              NaN              NaN   \n",
       "2         33.429              NaN              NaN              NaN   \n",
       "3         36.058              NaN              NaN              NaN   \n",
       "4         35.956              NaN              NaN              NaN   \n",
       "\n",
       "   Right ear lobe-x  Right ear lobe-y  Right ear lobe-z  \n",
       "0               NaN               NaN               NaN  \n",
       "1               NaN               NaN               NaN  \n",
       "2               NaN               NaN               NaN  \n",
       "3               NaN               NaN               NaN  \n",
       "4               NaN               NaN               NaN  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total number of features: \\t%s' % len(data_df.columns.values))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Features Where NaN Is Present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features before dropping NaN: \t79\n",
      "Total number of features after dropping NaN: \t58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Outer left eyebrow-x</th>\n",
       "      <th>Outer left eyebrow-y</th>\n",
       "      <th>Outer left eyebrow-z</th>\n",
       "      <th>Middle left eyebrow-x</th>\n",
       "      <th>Middle left eyebrow-y</th>\n",
       "      <th>Middle left eyebrow-z</th>\n",
       "      <th>Inner left eyebrow-x</th>\n",
       "      <th>Inner left eyebrow-y</th>\n",
       "      <th>Inner left eyebrow-z</th>\n",
       "      <th>...</th>\n",
       "      <th>Left mouth corner-z</th>\n",
       "      <th>Upper lip outer middle-x</th>\n",
       "      <th>Upper lip outer middle-y</th>\n",
       "      <th>Upper lip outer middle-z</th>\n",
       "      <th>Right mouth corner-x</th>\n",
       "      <th>Right mouth corner-y</th>\n",
       "      <th>Right mouth corner-z</th>\n",
       "      <th>Lower lip outer middle-x</th>\n",
       "      <th>Lower lip outer middle-y</th>\n",
       "      <th>Lower lip outer middle-z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANGER</td>\n",
       "      <td>-72.961</td>\n",
       "      <td>-1.725</td>\n",
       "      <td>22.958</td>\n",
       "      <td>-55.678</td>\n",
       "      <td>4.591</td>\n",
       "      <td>38.791</td>\n",
       "      <td>-31.920</td>\n",
       "      <td>-1.929</td>\n",
       "      <td>36.645</td>\n",
       "      <td>...</td>\n",
       "      <td>31.654</td>\n",
       "      <td>-11.424</td>\n",
       "      <td>-77.828</td>\n",
       "      <td>44.218</td>\n",
       "      <td>7.849</td>\n",
       "      <td>-78.691</td>\n",
       "      <td>29.980</td>\n",
       "      <td>-9.891</td>\n",
       "      <td>-86.283</td>\n",
       "      <td>39.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DISGUST</td>\n",
       "      <td>-76.565</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>6.126</td>\n",
       "      <td>-62.086</td>\n",
       "      <td>9.454</td>\n",
       "      <td>24.055</td>\n",
       "      <td>-35.614</td>\n",
       "      <td>2.066</td>\n",
       "      <td>25.073</td>\n",
       "      <td>...</td>\n",
       "      <td>6.895</td>\n",
       "      <td>-15.941</td>\n",
       "      <td>-66.863</td>\n",
       "      <td>29.844</td>\n",
       "      <td>14.277</td>\n",
       "      <td>-75.678</td>\n",
       "      <td>7.290</td>\n",
       "      <td>-15.118</td>\n",
       "      <td>-83.790</td>\n",
       "      <td>24.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FEAR</td>\n",
       "      <td>-76.163</td>\n",
       "      <td>6.390</td>\n",
       "      <td>10.784</td>\n",
       "      <td>-57.083</td>\n",
       "      <td>16.865</td>\n",
       "      <td>30.162</td>\n",
       "      <td>-33.708</td>\n",
       "      <td>14.082</td>\n",
       "      <td>32.408</td>\n",
       "      <td>...</td>\n",
       "      <td>25.992</td>\n",
       "      <td>-12.448</td>\n",
       "      <td>-60.169</td>\n",
       "      <td>45.930</td>\n",
       "      <td>9.749</td>\n",
       "      <td>-73.120</td>\n",
       "      <td>25.172</td>\n",
       "      <td>-12.362</td>\n",
       "      <td>-84.124</td>\n",
       "      <td>42.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAPPY</td>\n",
       "      <td>-72.140</td>\n",
       "      <td>8.896</td>\n",
       "      <td>9.353</td>\n",
       "      <td>-54.721</td>\n",
       "      <td>22.380</td>\n",
       "      <td>27.474</td>\n",
       "      <td>-29.789</td>\n",
       "      <td>15.802</td>\n",
       "      <td>28.937</td>\n",
       "      <td>...</td>\n",
       "      <td>17.507</td>\n",
       "      <td>-7.999</td>\n",
       "      <td>-51.207</td>\n",
       "      <td>40.242</td>\n",
       "      <td>22.196</td>\n",
       "      <td>-56.737</td>\n",
       "      <td>12.908</td>\n",
       "      <td>-7.063</td>\n",
       "      <td>-69.995</td>\n",
       "      <td>38.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SADNESS</td>\n",
       "      <td>-73.743</td>\n",
       "      <td>3.099</td>\n",
       "      <td>12.438</td>\n",
       "      <td>-58.607</td>\n",
       "      <td>15.144</td>\n",
       "      <td>29.381</td>\n",
       "      <td>-32.979</td>\n",
       "      <td>11.594</td>\n",
       "      <td>30.048</td>\n",
       "      <td>...</td>\n",
       "      <td>25.140</td>\n",
       "      <td>-11.017</td>\n",
       "      <td>-62.101</td>\n",
       "      <td>42.409</td>\n",
       "      <td>14.146</td>\n",
       "      <td>-67.281</td>\n",
       "      <td>23.486</td>\n",
       "      <td>-9.479</td>\n",
       "      <td>-74.060</td>\n",
       "      <td>41.452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label  Outer left eyebrow-x  Outer left eyebrow-y  Outer left eyebrow-z  \\\n",
       "0    ANGER               -72.961                -1.725                22.958   \n",
       "1  DISGUST               -76.565                -0.458                 6.126   \n",
       "2     FEAR               -76.163                 6.390                10.784   \n",
       "3    HAPPY               -72.140                 8.896                 9.353   \n",
       "4  SADNESS               -73.743                 3.099                12.438   \n",
       "\n",
       "   Middle left eyebrow-x  Middle left eyebrow-y  Middle left eyebrow-z  \\\n",
       "0                -55.678                  4.591                 38.791   \n",
       "1                -62.086                  9.454                 24.055   \n",
       "2                -57.083                 16.865                 30.162   \n",
       "3                -54.721                 22.380                 27.474   \n",
       "4                -58.607                 15.144                 29.381   \n",
       "\n",
       "   Inner left eyebrow-x  Inner left eyebrow-y  Inner left eyebrow-z  \\\n",
       "0               -31.920                -1.929                36.645   \n",
       "1               -35.614                 2.066                25.073   \n",
       "2               -33.708                14.082                32.408   \n",
       "3               -29.789                15.802                28.937   \n",
       "4               -32.979                11.594                30.048   \n",
       "\n",
       "             ...             Left mouth corner-z  Upper lip outer middle-x  \\\n",
       "0            ...                          31.654                   -11.424   \n",
       "1            ...                           6.895                   -15.941   \n",
       "2            ...                          25.992                   -12.448   \n",
       "3            ...                          17.507                    -7.999   \n",
       "4            ...                          25.140                   -11.017   \n",
       "\n",
       "   Upper lip outer middle-y  Upper lip outer middle-z  Right mouth corner-x  \\\n",
       "0                   -77.828                    44.218                 7.849   \n",
       "1                   -66.863                    29.844                14.277   \n",
       "2                   -60.169                    45.930                 9.749   \n",
       "3                   -51.207                    40.242                22.196   \n",
       "4                   -62.101                    42.409                14.146   \n",
       "\n",
       "   Right mouth corner-y  Right mouth corner-z  Lower lip outer middle-x  \\\n",
       "0               -78.691                29.980                    -9.891   \n",
       "1               -75.678                 7.290                   -15.118   \n",
       "2               -73.120                25.172                   -12.362   \n",
       "3               -56.737                12.908                    -7.063   \n",
       "4               -67.281                23.486                    -9.479   \n",
       "\n",
       "   Lower lip outer middle-y  Lower lip outer middle-z  \n",
       "0                   -86.283                    39.421  \n",
       "1                   -83.790                    24.378  \n",
       "2                   -84.124                    42.100  \n",
       "3                   -69.995                    38.018  \n",
       "4                   -74.060                    41.452  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total number of features before dropping NaN: \\t%s' % len(data_df.columns.values))\n",
    "data_df = data_df.dropna(axis=1, how='any')\n",
    "print('Total number of features after dropping NaN: \\t%s' % len(data_df.columns.values))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe why are we doing this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Separate features from their labels\n",
    "features = [x != 'Label' for x in data_df.columns.values]\n",
    "values = data_df.loc[:, features].values\n",
    "labels = data_df.loc[:,['Label']].values\n",
    "\n",
    "# Scale values (mean = 0 and variance = 1)\n",
    "values =  normalize(values, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe what dimensionality reduction is and why is it necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe what PCA is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In PCA we use the option ['mle'](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html), describe what it is and what it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANGER</td>\n",
       "      <td>0.115475</td>\n",
       "      <td>-1.625148</td>\n",
       "      <td>0.065469</td>\n",
       "      <td>0.114193</td>\n",
       "      <td>0.079739</td>\n",
       "      <td>1.031041</td>\n",
       "      <td>0.012079</td>\n",
       "      <td>-1.347167</td>\n",
       "      <td>0.986494</td>\n",
       "      <td>-1.195390</td>\n",
       "      <td>0.651152</td>\n",
       "      <td>0.667144</td>\n",
       "      <td>0.192260</td>\n",
       "      <td>-0.155829</td>\n",
       "      <td>1.118665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DISGUST</td>\n",
       "      <td>-0.073101</td>\n",
       "      <td>-1.483717</td>\n",
       "      <td>-0.133564</td>\n",
       "      <td>0.055333</td>\n",
       "      <td>-0.678214</td>\n",
       "      <td>0.639631</td>\n",
       "      <td>-0.328855</td>\n",
       "      <td>0.177782</td>\n",
       "      <td>-0.213121</td>\n",
       "      <td>-0.851841</td>\n",
       "      <td>-0.389660</td>\n",
       "      <td>0.403289</td>\n",
       "      <td>0.369033</td>\n",
       "      <td>-0.233596</td>\n",
       "      <td>0.912007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FEAR</td>\n",
       "      <td>0.061006</td>\n",
       "      <td>-1.113592</td>\n",
       "      <td>-0.500768</td>\n",
       "      <td>-0.805798</td>\n",
       "      <td>0.354913</td>\n",
       "      <td>0.951869</td>\n",
       "      <td>-0.296006</td>\n",
       "      <td>-0.947259</td>\n",
       "      <td>0.924113</td>\n",
       "      <td>-0.253905</td>\n",
       "      <td>0.758371</td>\n",
       "      <td>0.233441</td>\n",
       "      <td>0.275224</td>\n",
       "      <td>-0.997149</td>\n",
       "      <td>0.880709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAPPY</td>\n",
       "      <td>0.122492</td>\n",
       "      <td>-0.808946</td>\n",
       "      <td>-0.375718</td>\n",
       "      <td>0.094078</td>\n",
       "      <td>-0.797231</td>\n",
       "      <td>0.172728</td>\n",
       "      <td>-1.712192</td>\n",
       "      <td>0.133741</td>\n",
       "      <td>-0.739601</td>\n",
       "      <td>-1.063692</td>\n",
       "      <td>0.370619</td>\n",
       "      <td>0.576226</td>\n",
       "      <td>0.477188</td>\n",
       "      <td>-0.323621</td>\n",
       "      <td>-0.051475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SADNESS</td>\n",
       "      <td>0.079619</td>\n",
       "      <td>-1.151237</td>\n",
       "      <td>-0.303649</td>\n",
       "      <td>-0.640826</td>\n",
       "      <td>-0.257518</td>\n",
       "      <td>0.543922</td>\n",
       "      <td>-1.133558</td>\n",
       "      <td>-0.789340</td>\n",
       "      <td>0.129232</td>\n",
       "      <td>-0.789671</td>\n",
       "      <td>0.986112</td>\n",
       "      <td>0.462523</td>\n",
       "      <td>-0.489619</td>\n",
       "      <td>-0.546546</td>\n",
       "      <td>0.819136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label         0         1         2         3         4         5  \\\n",
       "0    ANGER  0.115475 -1.625148  0.065469  0.114193  0.079739  1.031041   \n",
       "1  DISGUST -0.073101 -1.483717 -0.133564  0.055333 -0.678214  0.639631   \n",
       "2     FEAR  0.061006 -1.113592 -0.500768 -0.805798  0.354913  0.951869   \n",
       "3    HAPPY  0.122492 -0.808946 -0.375718  0.094078 -0.797231  0.172728   \n",
       "4  SADNESS  0.079619 -1.151237 -0.303649 -0.640826 -0.257518  0.543922   \n",
       "\n",
       "          6         7         8         9        10        11        12  \\\n",
       "0  0.012079 -1.347167  0.986494 -1.195390  0.651152  0.667144  0.192260   \n",
       "1 -0.328855  0.177782 -0.213121 -0.851841 -0.389660  0.403289  0.369033   \n",
       "2 -0.296006 -0.947259  0.924113 -0.253905  0.758371  0.233441  0.275224   \n",
       "3 -1.712192  0.133741 -0.739601 -1.063692  0.370619  0.576226  0.477188   \n",
       "4 -1.133558 -0.789340  0.129232 -0.789671  0.986112  0.462523 -0.489619   \n",
       "\n",
       "         13        14  \n",
       "0 -0.155829  1.118665  \n",
       "1 -0.233596  0.912007  \n",
       "2 -0.997149  0.880709  \n",
       "3 -0.323621 -0.051475  \n",
       "4 -0.546546  0.819136  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use PCA to reduce dimensionality\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 15, whiten = True)\n",
    "principal_components = pca.fit_transform(values)\n",
    "principal_df = pd.DataFrame(data = principal_components)\n",
    "# Add the label to the dataframe with the principal components\n",
    "principal_labels_df = pd.concat([data_df[['Label']], principal_df], axis = 1)\n",
    "principal_labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the PCA 2d projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a11cd34a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "x_label = principal_labels_df.columns.values[1]\n",
    "y_label = principal_labels_df.columns.values[2]\n",
    "ax.set_xlabel(x_label, fontsize = 12)\n",
    "ax.set_ylabel(y_label, fontsize = 12)\n",
    "ax.set_title('3 Components PCA', fontsize = 15)\n",
    "\n",
    "targets = ['ANGER', 'DISGUST', 'FEAR', 'HAPPY', 'SADNESS', 'SURPRISE']\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y']\n",
    "for target, color in zip(targets, colors):\n",
    "    indexes_to_keep = principal_labels_df['Label'] == target\n",
    "    ax.scatter(\n",
    "        principal_labels_df.loc[indexes_to_keep, x_label],\n",
    "        principal_labels_df.loc[indexes_to_keep, y_label],\n",
    "        c = color,\n",
    "        s = 50\n",
    "    )\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe what TSNE is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANGER</td>\n",
       "      <td>2.366467</td>\n",
       "      <td>-5.952292</td>\n",
       "      <td>-5.817704</td>\n",
       "      <td>-0.516321</td>\n",
       "      <td>1.900749</td>\n",
       "      <td>-2.829597</td>\n",
       "      <td>-1.550068</td>\n",
       "      <td>-1.179924</td>\n",
       "      <td>2.064284</td>\n",
       "      <td>1.588390</td>\n",
       "      <td>1.871071</td>\n",
       "      <td>-0.678025</td>\n",
       "      <td>0.260862</td>\n",
       "      <td>6.342507</td>\n",
       "      <td>-0.145513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DISGUST</td>\n",
       "      <td>-0.553080</td>\n",
       "      <td>-8.393978</td>\n",
       "      <td>-5.530555</td>\n",
       "      <td>1.159727</td>\n",
       "      <td>3.700656</td>\n",
       "      <td>-4.151265</td>\n",
       "      <td>1.055790</td>\n",
       "      <td>-2.096505</td>\n",
       "      <td>4.206555</td>\n",
       "      <td>0.349276</td>\n",
       "      <td>3.538473</td>\n",
       "      <td>-1.545040</td>\n",
       "      <td>0.333859</td>\n",
       "      <td>0.354309</td>\n",
       "      <td>-1.023844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FEAR</td>\n",
       "      <td>27.137568</td>\n",
       "      <td>19.613581</td>\n",
       "      <td>-17.228455</td>\n",
       "      <td>0.163092</td>\n",
       "      <td>12.801679</td>\n",
       "      <td>11.829565</td>\n",
       "      <td>-3.108263</td>\n",
       "      <td>-16.574970</td>\n",
       "      <td>-30.612078</td>\n",
       "      <td>-0.751934</td>\n",
       "      <td>2.418499</td>\n",
       "      <td>-0.084304</td>\n",
       "      <td>-1.737079</td>\n",
       "      <td>1.558778</td>\n",
       "      <td>-0.953803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAPPY</td>\n",
       "      <td>1.087585</td>\n",
       "      <td>-4.325572</td>\n",
       "      <td>-1.411307</td>\n",
       "      <td>-1.658222</td>\n",
       "      <td>0.399386</td>\n",
       "      <td>-1.429610</td>\n",
       "      <td>0.380368</td>\n",
       "      <td>4.122686</td>\n",
       "      <td>0.704613</td>\n",
       "      <td>0.050273</td>\n",
       "      <td>0.743142</td>\n",
       "      <td>-0.176219</td>\n",
       "      <td>0.150796</td>\n",
       "      <td>0.495435</td>\n",
       "      <td>7.570835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SADNESS</td>\n",
       "      <td>-0.581712</td>\n",
       "      <td>-7.353347</td>\n",
       "      <td>-2.013272</td>\n",
       "      <td>-3.199156</td>\n",
       "      <td>1.728881</td>\n",
       "      <td>-2.171417</td>\n",
       "      <td>-3.087746</td>\n",
       "      <td>-0.166789</td>\n",
       "      <td>1.612997</td>\n",
       "      <td>-0.269918</td>\n",
       "      <td>2.642377</td>\n",
       "      <td>0.811108</td>\n",
       "      <td>0.299304</td>\n",
       "      <td>1.669997</td>\n",
       "      <td>3.405343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label          0          1          2         3          4          5  \\\n",
       "0    ANGER   2.366467  -5.952292  -5.817704 -0.516321   1.900749  -2.829597   \n",
       "1  DISGUST  -0.553080  -8.393978  -5.530555  1.159727   3.700656  -4.151265   \n",
       "2     FEAR  27.137568  19.613581 -17.228455  0.163092  12.801679  11.829565   \n",
       "3    HAPPY   1.087585  -4.325572  -1.411307 -1.658222   0.399386  -1.429610   \n",
       "4  SADNESS  -0.581712  -7.353347  -2.013272 -3.199156   1.728881  -2.171417   \n",
       "\n",
       "          6          7          8         9        10        11        12  \\\n",
       "0 -1.550068  -1.179924   2.064284  1.588390  1.871071 -0.678025  0.260862   \n",
       "1  1.055790  -2.096505   4.206555  0.349276  3.538473 -1.545040  0.333859   \n",
       "2 -3.108263 -16.574970 -30.612078 -0.751934  2.418499 -0.084304 -1.737079   \n",
       "3  0.380368   4.122686   0.704613  0.050273  0.743142 -0.176219  0.150796   \n",
       "4 -3.087746  -0.166789   1.612997 -0.269918  2.642377  0.811108  0.299304   \n",
       "\n",
       "         13        14  \n",
       "0  6.342507 -0.145513  \n",
       "1  0.354309 -1.023844  \n",
       "2  1.558778 -0.953803  \n",
       "3  0.495435  7.570835  \n",
       "4  1.669997  3.405343  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "tsne = manifold.TSNE(n_components = 15, init = 'pca', random_state = 0, method='exact')\n",
    "tsne_components = tsne.fit_transform(values)\n",
    "tsne_df = pd.DataFrame(data = tsne_components)\n",
    "# Add the label to the dataframe with the TSNE components\n",
    "tsne_labels_df = pd.concat([data_df[['Label']], tsne_df], axis = 1)\n",
    "tsne_labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the TSNE 2d projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xd8FcXex/HP7OnpIQkBEkLvKiChCFgBr12wd+z9Ecu1e1XsvZdruVhR7L2LICLSQaT3EkpIQgJJTj87zx8bSEJOECQhJOf3vi9e4Zxtk7343dnZ2RmltUYIIUTTZzR0AYQQQuwbEvhCCBEjJPCFECJGSOALIUSMkMAXQogYIYEvhBAxQgJfCCFihAS+EELECAl8IYSIEfaGLkBV6enpum3btg1dDCGEaFRmzZpVqLXO+Lv19qvAb9u2LTNnzmzoYgghRKOilFqzO+tJk44QQsQICXwhhIgREvhCCBEjJPCFECJG7FcPbYUQYm/5/WvJy3uOkpIJOBwZtGp1JenpJ6GU1G8l8IUQTcbWrX8wb97RmGYQrYMV300mLe04uncfF/OhH9u/vRCiydBas3DhGUQiZTvCHsA0yykq+o7Cwi8asHT7Bwl8IUSTUFo6g3C4JOoy0yxj/foX93GJ9j8S+EKIJiEU2gLYdrG8YN8VZj8lgS+EaBISEnpimv6oy5RykJx82D4u0f5HAl8I0SS4XC1JTx+BYXhqLFPKSevWNzRAqfYvEvhCiCaja9c3SEs7CcNwY7MlYbMl4nBkctBB3+LxtG/o4jU46ZYphGgybDY3PXqMIxBYT2npHByOVJKSDon57pjbSeALIZoclysLlyuroYux35HLnhBCxAgJfCGEiBES+EIIESMk8IUQIkZI4AshRIyQwBdCiBghgS+EEDFCAl8IIWKEBL4QQsQICXwhhIgREvhCCBEj6iTwlVIpSqmPlVKLlVKLlFKHKKWaKaV+Ukotq/iZWhfHEkII8c/UVQ3/WeB7rXVXoCewCLgNGK+17gSMr/gshBCigex14CulkoDDgP8BaK2DWusS4GTgrYrV3gKG7+2xhBBC/HN1UcNvDxQAbyil5iilXldKxQOZWuuNABU/m9fBsYQQQvxDdRH4duBg4GWtdW+gnD1ovlFKXa6UmqmUmllQIJMMCyFEfamLwM8D8rTW0yo+f4x1AchXSrUEqPi5OdrGWutXtda5WuvcjIyMOiiOEEKIaPY68LXWm4B1SqkuFV8NARYCXwIjK74bCXyxt8cSQgjxz9XVFIf/B4xVSjmBlcBFWBeTD5VSlwBrgdPr6FhCCCH+gToJfK31XCA3yqIhdbF/IYQQe0/etBVCiBghgS+EEDFCAl8IIWKEBL4QQsQICXwhhIgREvhCCBEjJPCFECJGSOALIUSMkMAXQogYIYEvhBAxQgJfCCFihAS+EELECAl8IYSIERL4QggRIyTwhRAiRkjgCyFEjJDAF0KIGFFXUxwKIWoRDsNXX8Eff0B6OpxzDmRnN3SpRCySwBeiHuXlweDBsGULlJaC0wn33AMPPwzXX9/QpROxRpp0hKhHw4dboV9aan0OBsHvhzvvhKlTG7ZsIvZI4AtRTxYtgoULIRKpuczng6ee2vdlErFNAl+IerJqldWEE43WsGTJvi2PEBL4QtST9u2tJpxolIJu3fZteYSQwBeinnTtCgccAPYoXSM8Hrjxxn1fJhHbJPCFqEeffw45OZCYaH12ucDthsceg379GrZsIvZIt0wh6lGrVrB0KXz3ndUrJy0NzjoLWrZs6JKJWCSBL0Q9s9nghBOsP0I0JGnSEUKIGCGBL4QQMUICXwghYoQEvhBCxAgJfCGEiBES+EIIESMk8IUQIkZI4AshRIyQwBdCiBhRZ4GvlLIppeYopb6u+NxOKTVNKbVMKfWBUqqWgWKFEELsC3VZwx8FLKry+VHgaa11J6AYuKQOjyWEEGIP1UngK6WygeOB1ys+K+Ao4OOKVd4ChtfFsYQQQvwzdVXDfwa4BTArPqcBJVrrcMXnPCAr2oZKqcuVUjOVUjMLCgrqqDhCCCF2tteBr5Q6AdistZ5V9esoq+po22utX9Va52qtczMyMva2OEIIIWpRF8MjDwJOUkodB7iBJKwaf4pSyl5Ry88GNtTBsYQQQvxDe13D11rfrrXO1lq3Bc4CftFanwtMAE6rWG0k8MXeHksIIcQ/V5/98G8FblRKLcdq0/9fPR5LCCF2W1kZPP64NZF827Zw1VWwalVDl6r+Ka2jNq03iNzcXD1z5syGLoYQogkrLbXmE16zBnw+6zu73ZpY/rffoGfPhi3fP6GUmqW1zv279eRNWyFETHnySVi9ujLsAcJh60Jw0UUNVqx9QgJfCBFTxowBvz/6skWLYP36fVuefUkCXwgRU7ze2pfZ7Vb7flMlgS+EiCmHHgoq2ptCWIHfvv2+Lc++JIEvhIgp99xjPaDdWVyctczh2Pdl2lck8IUQMaVXL/jqK8jJgfh4SEqCxEQr7EeNaujS1a+6eNNWCCEalaOOsnrqLFxo9dY58EBwuRq6VPVPAl8IEZOUgh49GroU+5Y06QghRIyQwBdCiBghgS+EEDFCAl8IIWKEBL4QQsQICXwhhIgREvhCCBEjJPCFECJGSOALIUSMkMAXQogYIYEvhBAxQgJfCCFihAS+EELECAl8IYSIERL4QggRIyTwhRAiRkjgCyFEjJDAF0KIGCGBL4QQMUICXwghYoQEvhBCxAgJfCGEiBES+EI0Zn/8AWefDYccAldfDUuWNHSJxH5MAl+IxuqBB2DoUPjgA5g6FV57DXr3hs8+a+iSif2UBL4QjdHChfDQQ+D1gtbWd+Ew+Hxw3nlQVtaw5RP7JQl8IRqj//0PQqHoywwDvvhi35ZHNAoS+EI0Rps2WTX6aEIhKCzct+URjcJeB75SqrVSaoJSapFSaoFSalTF982UUj8ppZZV/Ezd++IKIQAYNAji46Mvs9uhT599Wx5RndbWRdfrbeiSVFMXNfwwcJPWuhswALhGKdUduA0Yr7XuBIyv+CyEqAvnnw8uFyhV/XuHAzp0sC4IomG8/jpkZUF2NqSkwAknwNq1DV0qoA4CX2u9UWs9u+LvpcAiIAs4GXirYrW3gOF7eywhRIXERJg0Cdq2hYQESEoCj8eq2f/0U80Lgdg3nngCRo2CjRshELCa177/HnJz94tmNntd7kwp1RboDUwDMrXWG8G6KCilmtflsYSIeT16wIoVMH06rF8PXbtC9+4NXarY5fXCvffWbMaJRKC0FF56Ce6+u0GKtl2dPbRVSiUAnwDXa6237cF2lyulZiqlZhYUFNRVcYSIDUpB//5wyikS9g1txgyw2aIv8/vho4/2bXmiqJPAV0o5sMJ+rNb604qv85VSLSuWtwQ2R9tWa/2q1jpXa52bkZFRF8URQoh9z/43DSZ/t3wfqIteOgr4H7BIa/1UlUVfAiMr/j4SkI7BQoimq18/6x2IaDweGDky+rJ9qC5q+IOA84GjlFJzK/4cBzwCDFNKLQOGVXwWQoimyeGAF16wwr0qp9PqtXPppQ1Trir2+h5Daz0ZqK1LwJC93b8QQjQa554LzZvDXXfBnDnWuxIjR1oPcxMSGrp0ddtLRwghYt6wYdaf/ZAMrSCEEDFCAl8IIWKEBL4QQsQIacMXQtQP07ReRiorg4MPhlQZP7GhSQ1fCFH3xo+3uiIOGwanngqtWsH//Z81zIBoMFLDF0LUrQUL4KSTao4pM2aM1Sf9yScbplxCavhCiDr28MPWSJE783rh5ZetgcREg5DAF0LUrcmTa2+6cTis+XhFg5AmHSFimNaakgklbB63GTNgkj4inbQT0jDse1EXTE6ufVk4bE0KIhpEkwj8svllBNYG8HTyENcprqGLI8Q+FzEj/LzyZ5ZtWUab5DYc2+lY7Mau//M2QyZ/nfgX237fRqTMqpEXflqIu72b3r/1xp605/HgXealNPUU0o2l2Ex/tWUaiGQ1w9a5U61jsYj61agD37fSx/zh8/Gt8KEcCh3UJPZJpMcnPXA2dzZ08YTYJ5YULmHYO8Mo8W0hFAriMGy4XfF8f/6PHNzy4Fq3W/fkOrZO2orpM3d8FymL4F3iZfn1y+k6puvfHru83PoZHw+FXxSy8JyF6OBAepqdSVRLsGmrLd+0g+mEebcU4lxwKluTbuT56S+yumQ1vVv05voB19MlvcvenQjxt5TWuqHLsENubq6eOXPmbq0b8UeY1m4awc1BMKsscEBclzj6zuuLkmneRBMXioTIeSaH/NJN6J3+uSfjJu/2AhKc0QftmtJqCsGNwajLDLfB4JLBGK7Kpp2Iad0F2AwbkydbM/nNm2ct693T5JIFf9LFvxUARZjmI8+j1Yx8bF7Y0hfWnwaB5hCJ2HhmueKbTRE0Gruy47Q7eXfEu4zoNmIvz0hsUkrN0lrn/t16jfahbcGHBdZtqLnTghAEVgco+bWkQcolxL709dKvKS/bUiPsAcJBP++/fUut24YKQ7vcd3hbGIDZG2dz5JtH4nzAieOJdnS49wGGDoswe7bVJB8Ow4xZBtf7D2IJ1sVFZxaSf3Yxc16EmW/AyqutsAew2SKcnRZGY1U2wzqMN+TlvM/OoyxY9g/OgthdjTbwt07euqPdcWcRf4TSadL1SzR9C/L/otyMXksvd8Lc3z6sdVt3O3ety5RTYU+1M2fjHA574zAmblqI2etFdJ9XWTnuGgL+mlP5+bHxGjnWh9RiCDlq3X8bE5J91t8PS4c3c+GrQ7xM/6M5y5bdQDi827Okij3QaAPfke6AWv49GU4De7NG/XhCiN2SRSKecPRl7hDkrKn9TrfV1a1Q9pq3BkacQdZ1WRh2g5t+vInycBB6vwAJHSHigWW197KZSzMO4BYca5PAUcsdhAmeOSlc81sXzk9I5bau0CYeDAWG9rFhw8vMnj2QSMQffXvxjzXawG9xYYvau46ZkHGqzI8rmr7Tep1T6zIFjFyXFnWZf52fNfevQUesZpUybKwhjjJsLI1PgQvaYmqTX9f8ChmHgy0eDHvtUx3tOKYmlTn08t4FPw4Bv6v6CmXxcOf9lD76AUdNe4KLbn8fz+2PwNakHatoHcDvX83mze/v1jkQu6/RBn5c5zhy7sjBiDMq/xEaYHgMOr3cCUez2m8nhWgqElMy+XjDYNxhBari37yyg+HisMAxZFx4bY1tgpEg3/7nW9aoNZRpG/fRjVMYyFUczCkM5IWC1vQdYJCfX7FBck+wV3R3dmg4sASo2dlDYXIM32MjjEttJPGlATC1NyoAtnIwyoBRT8G0fmjtxBZJQIVcMOdguO45iFTGkWmWk5//Tt2eLNG4u2W2vastKYenkPd0Hr4VPhIOSiD7xmwSeyc2dNGE2Gc63v8+avYk0lZM5ojfE0kIZbIoty2ThyRwY9scnq1YT2vNU388xX2T7iPcKkz4cpPMzz/llKGjuaD3r5SWpvLFF1czecJpOLeUsvrYWzh0aHN+DW8DHbYuJADXroD/64XyG+iKOqMiQgLlPIb1kNimA3DM/ZwdCvPFNSmozGSaFaezfmU2Jjt1mQ47oCADpveDQ6bu+FrrCFPWTeGH5T/gtDkZ0W0E3TO61/fpbNIabbdMIYTliiVL2PLCRi591frsDILPA4XpcOtzisUnDCLZbufJKU9y98S78YasQc16lOby2JBFOOxBHBXt7T5fPPPmHcqDd4zjU/MURrW4kGb3jWZ6xxcIqsqHvJ2+i6flYy7+oCsKzTF8x6PcRleWABCxw8TT2nDZ/NdZs/BQPGaYc1jL2WxC1dYudPT3cOhkaLUBo2M+XxVk8fKSDXhDXmyGDYfh4JwDz+G1E1+TLtc72d1umY26hi+EgDWTirj+NXBV6awT54OWG+CuezTzjiijf2Ic9026b0fYA9w9eBlxnvJq+/J4yjnooN/od+RX/Hf8lRSUHsJTOZfxjvqITzgNPx4Azp1axr/4i34cjEHN3nJFOo3TvpnOtvJmmKadclyUkEAQA1eU5iCNhvFD4ffBqLCdUPZ6Pjv1XsrjrPKFzTBhM8y4+ePol9WPy/tcXhenLuY02jZ8IYTluPciOKP0zHREoONiSFgbZknhEqrezXdOgASPL+r+PJ5yTj75ZRbSnZ6HTCQScXBp2Qe8NvYXxl3o5b3zQxw1Zy65XIf1mLa6CC4ebXMr3kACpllZp/yVDHb11FdF7KjyBAi4YWVbHnjlcYwq7fqEHZSvOIjRb4+POhin+HtSwxeikeu4WGPU0jIbdmhyNiq2to4nbFb230ywg6lq6c8JJCaWoDDxeMowyuJg1DNkb0mFoBsbXg7hLux4a2xnYuNP+3940byUYLD6uFaFhoMpR87hsOGvYUsugQU9YMzF6ILMGs08Nm0j0ZfEwKUDmdxtMvx1Bnz9CqDYAGS8AY88AldfvdunSSA1fCEatYgvgqe8DFNFT3xPOAQtNtIupR05yTk7vl9eBg7bzq+pW0KmnblLB1NOAsFSD86CNLjzQbjyFcheR3MmUPMVd0u5U/PERT/RLfA1rVm743ulTEaPPpUBN92J7YAF0Ho9eujP6CMn1Frnjw/G0TWvK2BAzhTrZyAZAsmUlsJNN/kZM2blbpwlsZ0EvhCNmG+ZD3X4JJSzZhuHtoUx2i2nLOVLlFK8OfxN4mxxGBGDbWH4KR/8UV5WDys7Hx52JH1vfJfr774C1XUJHLAATvgKXrsMT9YU7ER/KcoZNnn9jV+ZWHAJS+jCdPrSiaUMHPgVBx88Hk+VZwbKbqLStqAd0d8U9hkhFpZ1hs/GwIT7oP0P1Zb7/W7uustg69Ype3DGYpsEvhCNmD3ZDll5qPPfAmcA7BXh6fGi0gvg3nsxTetiMCB7AB8s/4Ah84fQrLQZH0xvwaJVvQlqB2XE48XDZjK4RT2Gcke49IQHcKsAavudgCMC7gD+4dOJ4IpaHgOIC0NyOIQHPwczixn05boj7yAuLso4OUf9QrQ+/eXYuMbsz5SFV8GfI2HuSFh2fI318vOz+euvf/+TUxeTpA1fiEbM3caNe/Oh+C+9HoZMgPFDrLdWD5wPA6cALhz2NIrfuYGk+z6m5fLbuYM7dmx/82OwVG2lI8spI4GldAYUF/M6Ri3NNpsPs9PhvxGidM7BsdMmNjRJbGPg3IUsHxJlZ+lFBK98Ccer16BDdmymQURFeJaOrMYNoe199g0I15zrwjBMng/05uTJv1EaMekRF8f97dpxQnr6bp2/WCOBL0Qj1+Pec5j1+wvQfimc+17lgogBtgArFt2E0SyMfg7i//cRfHIn2//T35YE20hmNn2q7TONLThqeagbTg3z4bBenPzzLDSa+DD47TZc4UjU9ngFpE+DFQHQUW4M1PAv+TyzhIRf7qTNojWsbLaOnxcPQkd2PaeFYYRwDcrjM+NkQmHr6jO3vJwz587lyYULubJvXxgwACr67Gut2fj6RtY+tpZgXhBnlpPWN7em1WWtUEZs9OuXwBdif7ZwIbz7LpSUwBFHwIgR1rywVSQelEjflIksmHAV3pZfAgrsEbCZQATtNNmeneWX/AolfWH8cQD0nAsr20F4p2xdQA+O0BOJUzW7br65Gsbl/omnp+bcedClEFCakX/aSApEH8HWWQxGGCIOqjUk+yMwtQheMScRvOF8KJ4H8z+HJbfv8rQ4ieB2+Qlcs5qQql54r93OzR07MvL44/Ecdhh8/DHY7Sy9fCn57+djllu3If4VflbcuILSaaW7NdlLUyBt+ELsr265BXJz4fHH4eWX4ZJLoHNn2LChxqrxOWn0G/khhw4pZsBhS3DHtSVam4vp0TgueR4DPwZeTv00jCNcsw19in8QIRyYO9XZN3gN3tsYJmAPUeKBF/vDdcfDTUebmNHaeCoYYeg9CjzrwfCB6YVABH7ZDI8uhqAJzL8TMgbBQSPBVnuXUTsm57KGF90zCWREjzDDNPm1Y0f46Sd45hnKF5aTP7Yy7HecD6/J5nGbKZsfG+PwS+ALsYf8/jxWrbqHBQvOYPGKe9hQuoo6H6Lk22/hpZfA57NmGAEoK4N16+Css2rdzGbz4HJl4/Mvq3WdUHM//R2n0okXOWDzr3zw7/donZ9PgtdLYnkZjlCQ4ydN551FV7KJFnjxUE4cPlx8tqUZoSjjkofscOmJENxFoiSsgE4XpJB34Ul8/uixnD7Jw5PLDPzbT11gM0w7F4onwrCJ1kPonThsEW5mCRewlhZ/M2R+2GYDrxeeeYaCTwswQ9GfSZhBk4JPCna9syZCmnSE2AMFBZ+yaNF5mNoEHSCAA73uUa52PMD5nS7g1ObN6+ZATzxROWFsVZEIzJgBa9ZAmzZorfm0sJBn8/LYGAzSJyGBW1q3xsSOjei1ZGWCM+ylRdyvlGceRerKQUw57zXy2i/j8tPcZK9fzsvvF/Nb7/4Mf+ANOtmX05zNrKM1KyJ/gH4z6n4/OQCeXw83/WF91lS+V6uBO3mQp7kB5+YAZcUK8w8btiG3c6xjNT/0/hbTMAETin6H3iNgzVhYfAqoihFxTYXt+PUM+dwaxtPvVrh8EPDULEvQ4WDwX39ZHzZtQod01IfM1jkFMxD9YtDUSOALsZuCwUIr7M3Kdm0X1qBjV4buYuSiboTpy5l7EfrhcBmm6cOxalXtgxC4XLBuHTonh4sWL+bjggLKTSuwVvp8fFlUxBt5R9I8cwI4wiyiGwvpTgJlDA5PJnOSyaI2GbRu0YrkT0ex4CfN4m0d+D7pLuav/JAFbWBepsHhc2YzwvsVHwbOZuGfKdbQyJ1DYLwPZs22/YQAdCmq/Kywgj5ks/FS5Fqe5Tr8eKzxeCrmRjF+eIp+tr8YuLQ//znrP5VXCFsETrsAshJgXiewaxhQhJkUpGQSZGzx4wg6SCwzCDnArDKRi8fv46YPPyJl+wXT4aDZUUmse9Ko0aQDYMQbpB0bfd6ApkYCX4jdtKsJOTTQX4/npuWpnJGRscejOXq9y1i69Cq2bp0EGBzYAlJX1zLyjN8P7dvza0lJtbAH6/1Xn2niffQayu5cyS3pN7OadkS0HVtE86T9Fpz9TfRACLzUHdoaOG0B/JHmYHsJRpSiO3/HEdcfzOB1pfx+52BY1A8cymoAjnSDYzdDr9FU7T9vV9DcC8dWaUkK2WzM6NSdv7IP4J4J9+CN1JxMPaQdvBvuxPMr+9BzdU/+bPentcBwQfMh0CEeOlQ+szBDGncgSCbf4wgV0f/TVXw3/BjI6GeVJ+zFXPUOw7//rPIgpknSqq9IzO1J6bRSTH/l+TLcBom9E0kenLwH/281XhL4QuymQGBttdp9VR4CpFNAcTjMar+fdp4o7Qy17nc9s2f3Jxy2JhaJYDD6rPN4aM4HxO80Sph2OlFDh0KrVvxv0SK8ZvSmiJR1ydyf9wrL0wzCDuuysX2KWcNuwEfZmD9lQtCoGAGzorwffQRX9CLMTCbOuRe15ESra02V5hDn53dy/F+tmHns/axLX4dDQW4qPOC0VjXd8OYVg7lp2C0MnuAgZWkC24zkWptU1hCPK+TiuHlDsPf8C5fDwfyEU9nW5pLqK5pw0ILNDCkfhYt8vu5kZ2L7MObi32GpE2weCG0joDWnnQErn624YAaDqJdf5qCJU1hx0wo2vbWp4mRC5gWZdHyqY8wMtyyBL8Ruio8/EMNIwDRr9ujw4mENbTEBxx6Gx9q1TxCJlLO9xvwxp/JGz7PRlyXx6KuvYiqFMxwm4HRS3L49rd99F4CiUCjKO6qWPw+EPw+0EY4y8VvIAWQFIFBzInLCTojbQgIOQtNvIBCKr7FKEDsLVpzBK69kc9dZd3H0cbM5OtPq7r7gEZjevSujnHcSUG4y18Px35m8v4tn2nGEMQ6bxNE3v8jRTpPysAO752O+jvh5yX41JjYIKZRfcflTX7GWJDqTz8v9wpRv75FpBq0/AAoK42BmK+i7/eaguBibx0bnlzrT4akOhIvC2NPs2NzWOfD7Ydw4GDsWtIazz4ZzzoE9uG43CvUe+EqpY4BnARvwutb6kfo+phD1ISPjdJYvv4GIWb2pxQSCOPmNQ+nodpPtdte2i6iKir5A68rxZD7iDAK4ef7UU/ngyCM5ddIkkrxefj/gAOb26kVJcjI2YGhqKr+WlNSo5Q+bMYO0lNk4g5cRdNXsNqNtoNrX0g0xaybYA9zQsiUPh6IPnwCwlgQ8IQ93f3w3d3QZwcUTNNlfgr0Mwp2C9LtwMb8d1IuCDIg3TfraiphhpoFZvTwOIlzc42u4/WFwW+cg3mmV7Tj9Hd5tSYwpvxx+T8PxQXNuLXyBIE56MYdtxqlA/s5FA8CmYfP2a5XdDocfXrnMbcOWVXmxKymBfv1g/XqrUw/A1Knw6KMwbRqkptZ6Ghqdeu2WqZSyAS8CxwLdgbOVUjJHmWiUbDYPvXr9gt3RHC9xBHBSThzFNOMGnsZhuPlv5857vF+lqte7ttBsx983N2vGy8OH8+g55zC5Ywrepc8w7J1/cctPtzDU7cdjGNUuPne9/Taf/uduhs6bQshRy52GhuS4Qt6JO5MJHM6D3E4WedayuEJaezQ9WxQTjnZ7UCGx4qmrI6wY+2wcWWPAswkcZdBnzkq+u+U2zhw/nolHWOvfFlhGhhnEVaVdx02YHLyccMEjRBvQ3+PwcZrjI5yXHoh6sT3BwhS2koKPOGbQl7xPJ2ILR/8d/TZF980V1X+nE26+Oep6b74JWVmwbFll2IPVQWrNmlo3qzslJfDUU3DCCXDhhTB5snWLUU/qux9+P2C51nqltqow44CT6/mYQtSbhISeDDpkPR27vsu8pJt50riHkepjOqUezKTevTksJWWP95mZeR6qyvSBaRTVXGnjtzDrcsz1XzJh1U88O+1ZBrzak9GJ6+kWF4dDKdpt2sQdY8eSEPDTbe1acvICqCjt5s5QiLeeeYizfR9xBJO4kadZRDcG8xvO4o4c7csi1RHA6Yg+y4iLCMNZD0BLPZnOW3zEVekBagDxgQCvPPUUIWeQe0aDxx3kFccMLmMlB1BMb4q5nkW8zFTsXRbUmkTKZtKu+WL0To0RYZyEvK2wLx9aYxtHyEERP4q/AAAgAElEQVSfFX1Zt/VzVideif7mG+uFtZ28+CJcc031oK8qGLSaeGp5TLL3Fi2CDh3gP/+Bb76Bt9+Gf/0Lrryy3kK/vgM/C1hX5XNexXdCNFqGYadzixHcfPAD/HLYLZQdfiQ/9uxJn8TEf7S/rKzrcDozUcqqUZ/JB7io8nA4UADLnwUzwPYnn8FIEF/Yx81fX0ShrwQFnDZhAkaVdBp39zMkb9OVnWkiYPjhqk+/4KQ/pmCrCBU3ARIp4zNGcLkrjzO/uQIj4OZgcyugsVcZRM1DmC6UclrFHUFO+EfiIrUn4mHz5jGjH5w7Fj6+IETyYQs584BRjDd6cCfHcAQjcJXVkriA0wiweWt2je/thGimizn/+96k+CDRr0gpS+GwBYcx8teR3PXJvZh4WBs5m1/ea8+wYdCuHRx9tPXybTAId9xRe9hvFwpZ69aLU0+F4uLKQmht/X3sWPj663o5ZH234Ue736p26VJKXQ5cDpCTkxNldSGaNocjhT59ZrJ69Wjy89/l1Mg3rHIMZkK4FyEN4U3f11rjC2rYuuZbQtknkVRejjNcWdU+eOMPPPtoRy67+zSCs9Mg383ob1/g9pUvRd1XgnMrl+RPp2T9IWz98WhO9SxkdlkGdkwOogQPJv9iEwMpwoYmYITxOgtJiz40PgDuirQsTg7w3pkB1Kz/Y8y4dXiU1ZXT0JA+CfLOImpaKMNEV3l91yDC3dzHDTyNjTCukgD/fczgs/RbSSk6CkMbGLpyfdNr4nttDRPIJoLB6tXw++9wwQW7V4lu2dJ67aHOzZ8Pa9dGL0R5OTz3HJx4Yp0ftr4DPw9oXeVzNlBtIBCt9avAqwC5ubn113glxH7M6Uync+fn6dz5eQCOBOaXlfFFURGfb/QzU4eibqdDPu7833PcMP0VfurThzK3m0R/ZQK3L/8VY8qF8FQ38Nk5hPnYaunbY8ckv9l8rh3+JqsyVsENn9F8c0eKPh9LeX5H/q0WkkwInzZwoPgtayW/ddjIHZOp1qSz43fyR5iq+5NTtoEOMwv5M/AsV0xbx+kLwV2lqUnbqf5abhUqAIMHf8HXP1wGwH+5knN4j/gq0ytqZeP4gjeYweGYUSLNAFrhZx3W8MpeL4wZYz3L3ZW4OLj77h2DbdatTZt2XYAo4yXVhfoO/BlAJ6VUO2A9cBZwTj0fU4gm4YCEBA5ISKDlliGMWv0lZcGaPWviQ9BrkybB7+eY6dMxDYOA3Y6roqY/YOFCdLsU8Fn/qU9hIAP5HQ9RZsgyNbef9AnLW1ZeXDbmHQlF3ViCm3P0IDpSRhIhVpFAceo6mvX0MGpKBCfBak0/5cTxunkJhf85ku4dVpCb+BpLB/q5aapV5qrCydTauBx020k4agW28UFahjdxHu/UKLsyIzgooTkT2MQxNfZhI4KX6l1QtQZjFw3aNpv1wPbSS2tfB6yhjhYsgIQE6NJlDy4O3bpZfUFrO/jBB+/mjvZMvbbha63DwLXAD8Ai4EOt9YL6PKYQTc2ZPc7Eaas5NrxhQoofjqt4u9UTCmEqxbz27fE5nZQmJGDTJqfMnVAxVDK8zFWEowx+ZtphXrZmTlaVNC5Pg++fqph4xAAUy0lkNs0oxsHIeQN46+UPeTr8OZMZjB8XpSSwjUQe52Zu4BnQBgs7OXl8+NOUJG0gJUrGpfwJtlra0iPKzvx+WZhPzGNIpy+sPvlR2PGTzqQa32tgPXEU7TRDVygExx5bs5+93Q4ZGbBiBdx7b+0BrjXcfz80bw5DhliDmnbqZDUX7ZasLOsBbbT2Iper3roH1ftomVrrb7XWnbXWHbTWD9b38YRoauKd8UwcOZGsxCwSnYnE4yQhAB2K4dc3rD7n2yX6/czp1IkDxo1j3kcfsfw6N3dvfhRnxUtJG2nFv/iBfJqzlUS2kUDYCcXdYNiZOx140SnWVSUKA40PJwnBODqZqRzp+IXWrKMPs8iggNHci8bAQ5jenq0kGr05fokNI0prUvPxYFQ+j94hhJ11tGY+B6B7luE/Ix9ctQ/BbBJ9wpRn6VTju4QEuPhi+PFHq4u+2231t7/6ali8GNq0qfUwADz0EDzyiDWA6bZtVrP7ihVWhi9atOttd3j3XRg82LrqxMdDYqL18+234aCDdnMne0betBWiETgw80DW3rCWiasnsuaTMXR+5yMGrgjWaPY2AbvNxl0DBjCoZUtmJXej62dzuG3dwzzJzZSTwB8MpBV5DDN+ZsiRYznkvA+ZkRxi67yddhZIqpixpCYTg9KK2nY7vCR220LpvGYUkrFjHQcmWfh44KstrJn3AMdtPA/TWQAabFVuJGwB6Hkj/PkUhFKhjDgchFlIN+5lNNsb978fMACjlietETzkM6z6lwpWupNYFE7dMVgbWPPH5ORYPXYMAyZOjH7Oa+P3W2EfrYeP3w8PP2xl9t9KTISff7bahKZNg5SU6LcddUjGwxeikTCUwVHtjuKiU+9n0Hojahc4vy2ePkdey0UtWwKQ0/E/zH3Jw1XD7uNj+wiGqR9op1bQrvVCfngik7vuOp8/2h5ErxTok7rTc9PsqWCrpU+is5RV/cegKx4A3+ZYyInGejyEcRLBSYSjyOcZ5mJT0GWFg+zybWw4Eco6QLgi0zTW30OplVPWPsQdXMwYbuQZtlE5qNnWhAT+c/HFlO/0JrPX5WJTQmeK4gZWnqs4A0dzB8f83p0jjrBq8MnJ1s8jjoBff911G/6uLFpU+7aRCPzyyx7usEcP63bjlFPqfSwHqeEL0di0awcjR8I771SrZnpxMzXSjxPvGMod5XDnnZCRMYKy7rey5I6HUf+exO3eCXyYMILXbZcBTkI46MBKlIKrOsA1c6xpBzVAzu/Q6WvIPwiKurHjcqBC4C5h1WFPMG9TEj3X9KTPPM1AcyWXs4ptOEgkjHP7Q9wggMYgQFlHWHE1NJtpdcfUCgqOgJKKZ5Ragx8PG2gZtdfOk6efybKsLO556y26rFvHlsREXhw+nKdPPYPBswzun5JMnB/STkqj5UUtsSfZ+fFHa9iE1auhbVur+XxvJCRUzkkTTXzN4Yf2G6rOZ+rZC7m5uXrmzJkNXQwh9n9a43vyRbbc/AgtWU8JqbzAtTzInQRx4fHArFlWZxCwRuQcu/QNxhdt4Hf6soZ2AHRkGc8yiriKF73WeuH1lfB7kdU8pDToiAu2ZsO3z8Oaw6HFn3D6GajE9Rw751hu/sp6wGhSe5OBmzz6cSHrzo6w+gLQUYYbCvjdfPH1laz1tOL7o/sQcey0t1q6bm5nx+S61M3ckZ1CYmJvnM7M3T6de0Jr6NoVli6tuczjgdGj98GQDDtRSs3SWuf+3XpSwxeiMVKKj5pfyzUJ11JWVjMJQyF44w147DFg2TIcD9zPiC8/4ii7nbeO2crTp45ga3IaDkLoKl1RcuKspp3pxRAwrRo49gCkrYBzT4DSlpBsDaugAZ+z8o3g7ROe1MxkTUdeYDXnkPX9O6y5gKhvAjjDYV5rNpLwIz3I+qkA26ilbMyyLjrx5eD1RJ/dCsCJn7GcR3yxj4XbHJhmgObNz6BLl9cwjOgPc/8ppaw2+qFDrW6ZkYrnyB4PdOxoDdewv5I2fCEaqaKi7a/914zYcBjy84HZs60+3e++S2qJn7aFZdz97nusP+tcXn/kQVx5a1DaanpxbIG2z8Fbf1lhX4Nh7gh7AFcgjr7LDiGAwQbcPE0HypX1Wpf1x/pfs7ixpDMNsGMrjqPHvdYQD0ZFF03DC/ZSSHwklfCRJXD0RnrPD/Hfiw3ePxvePQ+euGmXlXs6sIJ0ivDgJRLZitZ+Cgo+YsmSK/7Jqf1b/ftbp/aCC6B1a+tO6oEHrFE24+Lq5ZB1Qmr4QjQC4fBWTDOAw1E5m1afPlaPk2hjvXg8sHIldD4kjdTgz1zFy5zLWByEUUB8IMgp88dz/YrxvNnseK4I/MTAS4OsdECw624UKOIg4G3Oa4tv5HUS2IITWnv5+oVV9J8HfebC5gzFN8eFcOuTmHX513jy16MIkzYNDjkDNg8BfybErYG0CXaezi0FNPx7JduabcUcm0DaFqsnUHqh9ScvixrVVHc4yCnqc3buom+aPjZvfp8OHR7D6cygrnXqZL2x25hIDV+I/VhZ2Txmzx7E779n8McfOUyd2o7Nmz8G4NBDoX17K/R35vPB1D80y4JtmE5/ruUFjuU7wlVSMXkDbBsN/tm5BN/sgn0bJPogsqtU0ArCLlgxDMdbvxDXopBSlwko+L/l6ASTqYPhxWvhozPBm+igJD6e2y67jAx+YxvdieDAUQpZn0OHV6Dl9xAJw7P9A1AxhMS00xXKXvlGrQLuGQ1xPqg6iKfbC30Cf3GUbXzU4hqGm7KyP3f3dDd5EvhC7Ke83mXMmTOYbdumoHUIrQMEAmtYvHgk+fnjUMrqxp2ba9Xok5Ks5oTtQ7SEI5WNIOUkMJUBvFdlZBPr3Vm46uvvOOSXlRgRyCqFzlFGZwYg5IKZV8CT6+H9r4mcGWTza2sxz8uDluVwcHHURDFtNj4/9FDs+IhnFeW0IYKTEHGEcFPocnHEhWE2prjBtLq/BIxiHjzlQfwOP2FlfddxBbx7peLCWW66L4b+U+GuB+G+5W9j1DI+kNYRHI4mNIPJXpJeOkLspxYtuoD8/PeINhms09mSQw7JQymjYl1YsgRKS623RctqmdDqEKYwhUHVvjOVImi34w5ZtetZLeGIC8HnqFLbD7mgNBtemUVCwM2QAYto0aaI1W1tTDwCAn8zyZdhmoSGDCGiFF91UrzQX5Pmc7A+KcjUbNAGoOxgc8MBD8KmH2HTN+QU5HDhzAs5MXgirtYusq/LZs0jayj5uaRy50f+Ajc/Dp6a4za4XDkMGLC6yc9ZK710hGjkioq+pbaZv8Phrfj9q/B4OgDWQ8Nu3WDChF2/UFRS5UWm7QytcYVCO7pV9tkIs1+BBw+DHzqAS0P3jOYUT76H9JTl/F/hVsw5CvdUG14PXPMi/PsJWNql9uMOWLAABTysb+We7hshZ5zV+6dqDuswhMvgr9sgYvX+KWxVSMZzGeT2q8yy1feurr7zXw+HIT/DwXN2hL5SDgzDRffuH9Qa9sFgAYFAHi5Xa5zO9NoL34RI4Auxn9p56sPq9I4JUwgG4bPP4KOP6BlOJOh7nRpPMAEHQY5gYo2uk9tc8OBguHtS5UiWnbbAm5+D6Xaw+HbF5gHroNu1cNY4iHh2XIfiKnplPn4znPJJ9JEYnP4IV74aZBI/cih2xnyRwG1+F5v7jgFblDeYIj4MDFx2F6d1P42r+15dbXH6iHRKZ5dieiu6Epk2uPt+OPQ3GP4lcf3DpKYPoXXr63G7aw6KEwptYfHii9iy5QcMw4VpBklLO46uXcdgt9e8IDYlEvhC7KeaNz+LDRteQkcZC9/lysHtzrFG7ho8GFatgrIymgEX2QfypjoPn67ead3E4Bi+q/adBoadD3+2gN9z4JWvoX0xmApKPDYKnniBVienkD/jRvR3g1BaRe0eaQvDoZNh4pFghMEetp7vegpg9NNeWs/vhcaGAtrpcnrEL2dztLAHDGWjeftzadflcg7IbM30baUUbl3B5qI/SXWnMHTkUOyP2wkGgpU3QKYNY8ZRtOp9Hh2v71jrOdXaZO7cI/B6l6B1kEjEegJcVPQ1c+ceRZ8+M5t0848EvhD7qTZtbmfz5nGEQkVAZTgaRhxdurxifbj5ZqvxvkrfzOfCVwFhXuPSHUMhG0T4khM4mp+rBbapYNAamJ4Nv7eBA66BVtvAGYE1zRw407Yw2X0WqRM7M27aexxTS2O9KwgtNoER1KS/l0L295oR5lhOL/CxkRHsfMfRPr8dk7s6CDlqXsxMw8Umdxc2lYf4Y+UKCHth7iiUfwNuw4ZNwasfvEr3h7pTMrEEZVcou6L1v1vT5o5dD3O5ZcuP+P2rsKbYrqR1EJ9vKSUlE0hNPWqX+2jMpJeOEPsppzOT3Nw5tGx5MTZbEobhITV1GL16/UpKyuHWK57vvFOjI76dCC9xNcuprOnew70cxUTsOz0TsGm491dwVqlsb0iC1amgtZ/AlpncvXo17Ua0A2Xgt1d5MJpQCue8C69dinrlMtr1GUfGlmLcU2z8uflA7i94kAE8xe30ZjbVJ3c/bu5x1aYirMZwQVr/ig8KbB7oejs64sMXKqMsWMalky+FN2HgpoH0nd+XQQWDaHtXW5Sx69p5SckvRCLRn2hHImWUlEzc5faNndTwhdiPuVwt6dLllcoafVU+nzWGQi1yWMf2wQ5O52PcUWa5Aqvppc8G+KPGlNIGnW1r8RSPxT3gJo7JOAY/FYGfugVeuRwSS8EdxAYcFsrjoC3fceXmmUS0gwgOgsBUXMwlldNZx8WsBqBZWTNGfzia28+5Hb19kHzDZfXSOegJUFXuCJQBnizwZIPPmjzdF/Ix9O2hJLuT6ZfVj1vdt9KzRc+/OZtgsyVixV7N5iSlnBXLmy6p4QvRWMXHW7N21MKf2Yb4eIXHA5FaZooCa6yaaC9bOQ2Tm5rP5TL9HNOmtaHdf6fT8qyW+DAIX/0SpJSAu/Luwu3wk9ZsI5dddvvOR8CPjQ9ozWoqxx3IXdmPPiv6VK7W7jIY8CEktK9ZGB0GR+VdgkZT6CtkRfEKPljwAQP/N5Avl3xZ6++4XfPmZ2IYVjPXJjKZTw+KK+4+lDLIyDj9b/fRmEngC9FYKQW33VZt8JbvOsLgiyHjFhhwXZhHv3+b++/XLOl7PiF79PZ3h8vNnOzqy9wGnNgSOseHcOPHNP2sWTea7GfWc0N2f9Thk8BRs8uowxFi6ND3iDY8WgTFj7TY8TnggpRQZZt7XHx27QOdKQf41kVdZGoTb9jLBZ9dQDBSy/j9248R1xkj89/8Hy8wkre4jUc4kw+4mwdIyboVj6ftLrdv7CTwhWjMbrjBmjzD5eKxI52cdobV26YwDuaF8rh10tX82X4kp/x4BY7sFjXHYYiLw/PKGJ4e/ja25APBkUKXRMVtXeGaDtVXNU0va9Y8wHlXmLVOfQjgdPpQKlrgG5RUaUW2RWBxX6vzfpw9jkc6H4QrWht8xA8Fv0Jo6y5PhUbzy6pdzz7ij0Q4e8uxLKI7QVyUk0AIJ9PUQK7ZetIut20KJPCFaMyUguefJ3/+NO45XOPdqYJcHirnk0WfMKN8KcycCZdeak2tZ7dbYzJ8/jmcfTbX9Dyd5VdM45aT3+Ppgz0cnhF9Am+vdwnXX++huLhGg/8Oa9Z0R0d5IOshTE+s0A444M+eirwe3emZ2ZMvzv6Ca7v/i7ttL+PBSxzleCjHoQPYSmbiXPHk354KrTXbAtt2uc7HBQWUhEJEdupcGtSKOWVlzNi26+0bO3loK0QT8MXWaRgOR9SHuP6wn3f+fId+xz0PL71k/YmircfDA537MaUwQm0jrjidLUhIgH79HmL5skswbNUndvX743j99QdrbKcwcRMhN66AQBhm5MKDd8EBaZ2Ye+xcwOoyOcj8hs/5lBn0xUsc3dVCkpI28GWOncllXTBwsbxocdSmm5AZYkD2gF2ep5+Kiykzo9+dhLTm961b6ZuUtMt9NGYS+EI0Ab6Qj4gZfRgGU5uUBkt3az8ORxqpqUPZsuVHIEQxKXiJI5N8nIab1q1vgvJyckb/hLEtyKqLsJrrHQ5wu9m48UkWLhxesTcNRggcBjrbR8pFC3jMbrKqHRQ0hzjD4PJWrXYcu7R0NpGIDycRBjGlSqHg3NZh/t3ycJplP0DnFzoTioR2zKcL4LF7OKHzCeQk137nAZBit2MA0SLfoRSJ9qYdiU37txMiRhze9nBshi3q0DsJzgSO7Xjsbu+ra9cxfDpzBA8Ez2MpHbARwU6EKz3zeLT5BTD4UJgzh+xAmJZfQGl3wKFISjmYQ3+8lAsusJ4jB4MKun0Cx34Jx4xklXKwyrB6CznRdPJ4uLRisnWwLjaG4cY0y2uUSSkHTmcLMuIzmHzRZM78+ExWlazCYTjwh/2c0eMM/nvCf//2dxvZogWvb9yIN0otPwIMT2/aY+rIaJlCNBFHv3M0v639DX+48uUoh+EgJzmHhdcsxGnbvan+NgQC9Jg+na2RMLpKW7c7CNfnlfPQqLNQ0YbjjI+H8eOhf39OOgm+/tqa/5VWM+HYsTCoA2R0xOFP4IG+rbk2O5s4W2V30VComD/+yMI0fTV2bRhu+vZdgMdT2WVzceFiCr2FdEvvRlpc2m79bgDXLl3Km5s2UV4R+grwGAaPt2/P1dnZu72f/cnujpYpD22FaCK+OOsLzj7gbNx2N4nORFw2F0PbD2XKJVN2O+wBnsnLw2ua1cIewO+EZ1s5KQ9HHwMHnw9+/BGAhx+28h+ADbnwv6fh4muJO/MYfkgbzC1t2lQLewCHI7ViDloPlUMxGBhGHO3aPVAt7AG6pndlcM7gPQp7gOc7deLdbt04NDmZti4XxzZrxvcHHdRow35PSJOOEE2Ex+FhzMljeOaYZ1i3dR2ZCZmkx+15E8VXRUUEa7nzt4c1szp34fB5UWaRstnAaV1YevSAyZNh1CjrJ0DPnvDUU3D44bUfOzPzXBISepGX9wxlZX/h8XQkO3sUSUl99/j3qI1SiuEZGQzPqPtpD/d3EvhCNDFJriR6NO/xj7d372JA/Yiy4QzW0gffbodTTtnxsWdPmDgR/H4wzd2f3Ds+vgddury2ByUWu0uadISoR9u2zWDt2sfIy3sOvz+voYuzWy5p0QKPjj4ImTNgo/XSbCLGTm/txsdbL4B16lRjG7d798Ne1C+p4QtRDyIRL/PmHU9p6XRMM4hSdlauvJXWrW+hXbvRDV28Xbq4ZUteXrOe5WU+gq6KL01rCORbHocVjptxDxtM+uI3YMMGaN3aGuJh5MgGLbf4exL4QtSDpUuvobR0KqZp9ZjROozWsG7dEyQk9CIjY0QDl7B2cTYb0/r34dYnZvFRBx8+N3RbBBe+Cd0XgZFsJ+n1f0PmHQ1dVLGHJPCFqGPhcCkFBeN2hH1Vpull7dqH9uvAB0iw23luVC7XXLqEgk8LMFwGOqxxdXTR4+MeODN3v9eP2H9I4AtRxwKB9RXzzdYMfACfb8W+LdA/ZPPY6D62O8H8IOULynGkO4g/ML5JTwHY1EngC1HHnM4WmGbtw/S6XFn7sDR7z5nplBp9EyG9dISoYw5HCmlpx6NUzZA0jDhat765AUpV/0KhIrze5Zhm9Jm1RMOTGr4Q9aBLl9eYM+dQAoG1FXOoGhiGm+bNzyQz8/yGLl6d8vvXsHjxRWzdOqViNilFdvaNtG17N0pJnXJ/IoEvRD1wOJrRt+88ioq+YcuW7zGMeDIzzyExsXdDF61OhULFzJrVj1CoEDCJRKza/bp1jxMOb6FTp+catoCimr26/CqlHldKLVZKzVNKfaaUSqmy7Hal1HKl1BKl1L/2vqhCNC5K2UhPP4nOnV+iY8fHm1zYA2zc+DqRSCk7Dzhsml42bnyNYLCgYQomotrb+62fgAP0/7d3f6FV12Ecx9+fM/9ArXKh1kppSvNiUpqoCBFaSliEdlHhTY2MJKnQIMr0phtBLYykvJAUFAwxFPUiyT9UF8E0EU1NyFVUa5bbRRZIyujp4vcdHufZOZvnuN+/5wWHfff9HY/Pw489++17fuf7mD0I/AC8AyCpBVgETAbmAxsl9d9F2TmXSt3de0rubgkgjeDixW+GOCJXTlUF38wOmFnv1nltQO92cwuBHWZ22cx+BtqBmdX8X8655CkUyu+ZUOi7BYOLVS3fUVkM7A/je4HiFvMdYe46kpZIOibpWFeX//nnXJo0Ni6mULi1n6PGqFFzhjIcV0HFgi/pkKTTJR4Li56zCugBtvdOlXipkvutmtkmM5tuZtPH5HC7UufSbMyYZ6ivnxL2sL+qULiF5uaPqavzK/wkqXiXjpnNK3dcUivwFDDXrrbP6gDGFz1tHNB5o0E655KpUBjOlCmH6ejYQGfnRnp6/qK+fipNTe/S0DAn7vBcH1W1OJQ0H1gPzDazrqL5ycCnROv29wCHgWYzK91lOfAWh845N3gDbXFY7X34HwEjgYNhf402M3vFzM5I2gl8T7TU82qlYu+cc+7mqqrgm9n9ZY6tBlZX8/rOOedqxz/37JxzOeEF3znncsILvnPO5URVd+nUmqQu4Je44yhjNNAddxA14HkkS1bygOzkkrY87jOzih9kSlTBTzpJxwZy61PSeR7JkpU8IDu5ZCWPvnxJxznncsILvnPO5YQX/MHZFHcANeJ5JEtW8oDs5JKVPK7ha/jOOZcTfoXvnHM54QW/AklTJbVJOhH27Z8Z5iVpQ2jj+J2kaXHHOhCSXg9tJ89IWlc0n7qWlJLelGSSRofvU3VOstQiVNL8EGu7pBVxxzNQksZL+lLS2fAzsSzM3ynpoKRz4WtD3LHWhJn5o8wDOAA8EcZPAl8VjfcT7f0/CzgSd6wDyOVR4BAwMnw/NnxtAU4SbYQ3AfgRqIs73gq5jAe+IPrcxug0nhPgcWBYGK8F1qbxfAB1IcaJwIgQe0vccQ0w9kZgWhjfRtSqtQVYB6wI8yt6z03aH36FX5kBt4fxHVzd138hsM0ibcAoSY1xBDgIS4E1ZnYZwMwuhPk0tqT8AHiLaxvrpOqcWHZahM4E2s3sJzO7AuwgyiHxzOy8mR0P43+As0Td+RYCW8PTtgJPxxNhbXnBr2w58J6k34D3CY3aGUQbxwSZBDwi6YikryXNCPOpykXSAuB3MzvZ51Cq8ujjhlqEJkTa4i1JUhPwEHAEuMvMzkP0SwEYG19ktVPtfviZIOkQcHeJQ6uAucAbZrZL0nPAZmAeg2jjOJQq5DIMaCBa7pgB7JQ0kQTmUiGPlUTLIdf9sxJzic3DzPaG59xwi9CESFu815FUD+wClpvZ36G/R+Z4wad8G+T6v0UAAAFqSURBVEdJ24Bl4dvPgE/COJFtHCvkshTYbdHC5FFJ/xHtGZK4XPrLQ9IDROvaJ8MP5TjgeHgzPTV59MpIi9C0xXsNScOJiv12M9sdpv+U1Ghm58Oy4IX+XyE9fEmnsk5gdhg/BpwL433AC+HOkFnAxd4/ARNsD1EOSJpE9AZbN1EuiySNlDQBaAaOxhZlGWZ2yszGmlmTmTURFZtpZvYHKTsnoUXo28ACM7tUdCg15yP4FmiWNEHSCGARUQ6Jp+iqYTNw1szWFx3aB7SGcSuwd6hjuxn8Cr+yl4EPJQ0D/gWWhPnPie4KaQcuAS/GE96gbAG2SDoNXAFaw1VlVlpSpu2cZKJFqJn1SHqN6K6pOmCLmZ2JOayBehh4Hjgl6USYWwmsIVryfAn4FXg2pvhqyj9p65xzOeFLOs45lxNe8J1zLie84DvnXE54wXfOuZzwgu+ccznhBd8553LCC75zzuWEF3znnMuJ/wFZnF4tGRcFBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103e467b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(tsne_components[:,0], tsne_components[:,1], c=colors, s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe why this is important (i.e. make sure we train the models with the same number of samples per label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0    1    2    3    4    5    6    7    8    9    10   11   12  \\\n",
      "Label                                                                       \n",
      "ANGER      71   71   71   71   71   71   71   71   71   71   71   71   71   \n",
      "DISGUST    69   69   69   69   69   69   69   69   69   69   69   69   69   \n",
      "FEAR       70   70   70   70   70   70   70   70   70   70   70   70   70   \n",
      "HAPPY     106  106  106  106  106  106  106  106  106  106  106  106  106   \n",
      "SADNESS    66   66   66   66   66   66   66   66   66   66   66   66   66   \n",
      "SURPRISE   71   71   71   71   71   71   71   71   71   71   71   71   71   \n",
      "\n",
      "           13   14  \n",
      "Label               \n",
      "ANGER      71   71  \n",
      "DISGUST    69   69  \n",
      "FEAR       70   70  \n",
      "HAPPY     106  106  \n",
      "SADNESS    66   66  \n",
      "SURPRISE   71   71  \n",
      "Total number of inputs: 453\n"
     ]
    }
   ],
   "source": [
    "rows, cols = tsne_labels_df.shape\n",
    "print(tsne_labels_df.groupby('Label').count())\n",
    "print('Total number of inputs: %s' % rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Explain output from above (i.e. from the table above we can see that some emotions have more samples than others, this is a problem because...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe how we are using holdout to account for class imbalance and the 80/20 partition as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(df):\n",
    "    '''\n",
    "    Split data into training and test sets\n",
    "    '''\n",
    "    # Shuffle data frame\n",
    "    df = df.sample(frac=1)\n",
    "    \n",
    "    # Select same number of samples per class for train set, remaining go to test set\n",
    "    num_of_train_inputs = int(rows * 0.8 / 6)\n",
    "    train_df, test_df = (pd.DataFrame(columns=df.columns.values), pd.DataFrame(columns=df.columns.values))\n",
    "    for x in targets:\n",
    "        train_df = train_df.append(df.loc[df['Label'] == x][0:num_of_train_inputs], ignore_index=True)\n",
    "        test_df = test_df.append(df.loc[df['Label'] == x][num_of_train_inputs:], ignore_index=True)\n",
    "\n",
    "    # Shuffle data frames (becuase they were appended in a per label fashion)\n",
    "    train_df = train_df.sample(frac=1)\n",
    "    test_df = test_df.sample(frac=1)\n",
    "    \n",
    "    # Split train and test datasets into labels/features\n",
    "    train_values   = train_df.iloc[:,1:].values\n",
    "    train_labels = train_df.iloc[:,:1].values.ravel()\n",
    "\n",
    "    test_values   = test_df.iloc[:,1:].values\n",
    "    test_labels = test_df.iloc[:,:1].values.ravel()\n",
    "    \n",
    "    return (train_values, train_labels, test_values, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-Nearest Neighbors (kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe what kNN is and its hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Explain choice of hyper-parameters (``n_neighbors``)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the experiments below, we also need to print the confusion matrix and confidence scores (for both the PCA and TSNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a kNN model using the PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN classifier accuracy using PCA components: \t0.63%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Get train/test values and labels using the PCA components\n",
    "train_values, train_labels, test_values, test_labels = get_train_test_split(principal_labels_df)\n",
    "\n",
    "kNNClassifier = neighbors.KNeighborsClassifier(n_neighbors=15).fit(train_values, train_labels)\n",
    "predicted_labels = kNNClassifier.predict(test_values)\n",
    "knn_pca_acc = accuracy_score(test_labels, predicted_labels)\n",
    "print('kNN classifier accuracy using PCA components: \\t%.02f%%' % knn_pca_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a kNN model using the TSNE components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN classifier accuracy using TSNE components: \t0.25%\n"
     ]
    }
   ],
   "source": [
    "# Get train/test values and labels using the TSNE components\n",
    "train_values, train_labels, test_values, test_labels = get_train_test_split(tsne_labels_df)\n",
    "\n",
    "kNNClassifier = neighbors.KNeighborsClassifier(n_neighbors=15).fit(train_values, train_labels)\n",
    "predicted_labels = kNNClassifier.predict(test_values)\n",
    "knn_tsne_acc = accuracy_score(test_labels, predicted_labels)\n",
    "print('kNN classifier accuracy using TSNE components: \\t%.02f%%' % knn_tsne_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe what SVM is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the experiments below, we also need to print the confusion matrix and confidence scores (for both the PCA and TSNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a SVM model using the PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM classifier accuracy using PCA components: \t0.82%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Get train/test values and labels using the PCA components\n",
    "train_values, train_labels, test_values, test_labels = get_train_test_split(principal_labels_df)\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm.fit(train_values, train_labels)\n",
    "predicted_labels = svm.predict(test_values)\n",
    "svm_pca_acc = accuracy_score(test_labels, predicted_labels)\n",
    "print('SVM classifier accuracy using PCA components: \\t%.02f%%' % svm_pca_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a SVM model using the TSNE components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM classifier accuracy using TSNE components: \t0.23%\n"
     ]
    }
   ],
   "source": [
    "# Get train/test values and labels using the TSNE components\n",
    "train_values, train_labels, test_values, test_labels = get_train_test_split(tsne_labels_df)\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm.fit(train_values, train_labels)\n",
    "predicted_labels = svm.predict(test_values)\n",
    "svm_tsne_acc = accuracy_score(test_labels, predicted_labels)\n",
    "print('SVM classifier accuracy using TSNE components: \\t%.02f%%' % svm_tsne_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe what a MLP is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Explain choice of hyper-parameters (``solver``, ``activation``, ``hidden_layer_sizes``, and ``max_iter``) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the experiments below, we also need to print the confusion matrix and confidence scores (for both the PCA and TSNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a MLP model using the PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP classifier accuracy using PCA components: \t0.84%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Get train/test values and labels using the PCA components\n",
    "train_values, train_labels, test_values, test_labels = get_train_test_split(principal_labels_df)\n",
    "\n",
    "mlp = MLPClassifier(solver='adam', activation='identity', hidden_layer_sizes=18, \n",
    "                    max_iter=300, batch_size=64)\n",
    "mlp.fit(train_values, train_labels)\n",
    "predicted_labels = mlp.predict(test_values)\n",
    "mlp_pca_acc = accuracy_score(test_labels, predicted_labels)\n",
    "print('MLP classifier accuracy using PCA components: \\t%.02f%%' % mlp_pca_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a MLP model using the TSNE components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP classifier accuracy using TSNE components: \t0.27%\n"
     ]
    }
   ],
   "source": [
    "# Get train/test values and labels using the PCA components\n",
    "train_values, train_labels, test_values, test_labels = get_train_test_split(tsne_labels_df)\n",
    "\n",
    "mlp = MLPClassifier(solver='adam', activation='identity', hidden_layer_sizes=18, \n",
    "                    max_iter=300, batch_size=64)\n",
    "mlp.fit(train_values, train_labels)\n",
    "predicted_labels = mlp.predict(test_values)\n",
    "mlp_tsne_acc = accuracy_score(test_labels, predicted_labels)\n",
    "print('MLP classifier accuracy using TSNE components: \\t%.02f%%' % mlp_tsne_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe what a Random Forest is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Explain choice of hyper-parameters (``n_estimators``, ``n_jobs``, ``criterion``, ``oob_score``, ``max_depth``, ``max_features``, and ``min_samples_leaf``) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the experiments below, we also need to print the confusion matrix and confidence scores (for both the PCA and TSNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Random Forest model using the PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier accuracy using PCA components: \t0.66%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Get train/test values and labels using the PCA components\n",
    "train_values, train_labels, test_values, test_labels = get_train_test_split(principal_labels_df)\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=10, n_jobs=1, criterion='gini', max_depth=6, max_features='sqrt')\n",
    "random_forest.fit(train_values, train_labels)\n",
    "predicted_labels = random_forest.predict(test_values)\n",
    "random_forest_pca_acc = accuracy_score(test_labels, predicted_labels)\n",
    "print('Random Forest classifier accuracy using PCA components: \\t%.02f%%' % random_forest_pca_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Random Forest model using the TSNE components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier accuracy using TSNE components: \t0.20%\n"
     ]
    }
   ],
   "source": [
    "# Get train/test values and labels using the PCA components\n",
    "train_values, train_labels, test_values, test_labels = get_train_test_split(tsne_labels_df)\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=10, n_jobs=1, criterion='gini', max_depth=6, max_features='sqrt')\n",
    "random_forest.fit(train_values, train_labels)\n",
    "predicted_labels = random_forest.predict(test_values)\n",
    "random_forest_tsne_acc = accuracy_score(test_labels, predicted_labels)\n",
    "print('Random Forest classifier accuracy using TSNE components: \\t%.02f%%' % random_forest_tsne_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Summary of our work and what configuration (model, PCA/TSNE, etc) produced the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN with PCA classifier accuracy: \t0.63%\n",
      "SVM with PCA classifier accuracy: \t0.82%\n",
      "MLP with PCA classifier accuracy: \t0.84%\n",
      "Random Forest with PCA classifier accuracy: \t0.66%\n"
     ]
    }
   ],
   "source": [
    "pca_models = {\n",
    "    'kNN with PCA': knn_pca_acc,\n",
    "    'SVM with PCA': svm_pca_acc,\n",
    "    'MLP with PCA': mlp_pca_acc,\n",
    "    'Random Forest with PCA': random_forest_pca_acc\n",
    "}\n",
    "\n",
    "for model, acc in pca_models.items():\n",
    "    print('%s classifier accuracy: \\t%.02f%%' % (model, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN with TSNE classifier accuracy: \t0.25%\n",
      "SVM with TSNE classifier accuracy: \t0.23%\n",
      "MLP with TSNE classifier accuracy: \t0.27%\n",
      "Random Forest with TSNE classifier accuracy: \t0.20%\n"
     ]
    }
   ],
   "source": [
    "tsne_models = {\n",
    "    'kNN with TSNE': knn_tsne_acc,\n",
    "    'SVM with TSNE': svm_tsne_acc,\n",
    "    'MLP with TSNE': mlp_tsne_acc,\n",
    "    'Random Forest with TSNE': random_forest_tsne_acc\n",
    "}\n",
    "    \n",
    "for model, acc in tsne_models.items():\n",
    "    print('%s classifier accuracy: \\t%.02f%%' % (model, acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
