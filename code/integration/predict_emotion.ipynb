{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output For ES Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from constants import get_all_emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of Input from CV Group, what we expected from them with 25 landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will be replaced with the reading data from CV Group\n",
    "# Sample data, do not skip\n",
    "data_df = pd.read_csv(r'../../data/lm3.csv')\n",
    "data_df = data_df.dropna(axis=1, how='any')\n",
    "features = [x != 'Label' for x in data_df.columns.values]\n",
    "all_values = data_df.loc[:, features].values\n",
    "r = all_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-72.961,  -1.725,  22.958, -55.678,   4.591,  38.791, -31.92 ,\n",
       "        -1.929,  36.645,  -1.467,  -1.246,  39.396,  19.511,   4.733,\n",
       "        39.521,  38.267,   0.895,  23.847, -62.234, -13.599,  23.387,\n",
       "       -30.594, -13.468,  27.897,  -1.368, -12.608,  28.601,  30.963,\n",
       "        -9.038,  19.359, -20.506, -20.528,  43.981,  -6.559, -20.715,\n",
       "        40.831, -30.866, -52.014,  39.217, -12.796, -44.354,  60.519,\n",
       "         4.687, -50.481,  37.689, -28.704, -81.568,  31.654, -11.424,\n",
       "       -77.828,  44.218,   7.849, -78.691,  29.98 ,  -9.891, -86.283,\n",
       "        39.421])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PCA Model\n",
    "We are loading the PCA model here which we used while training our classifier in order to apply the same dimensionality reduction to the given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.25785733 -0.00609646  0.08113771 -0.19677609  0.01622542  0.13709439\n",
      "  -0.11281103 -0.00681743  0.12951004 -0.00518464 -0.00440359  0.13923257\n",
      "   0.06895539  0.01672728  0.13967434  0.13524248  0.00316309  0.0842796\n",
      "  -0.21994618 -0.04806132  0.08265387 -0.10812471 -0.04759834  0.09859303\n",
      "  -0.00483476 -0.04455894  0.10108109  0.10942882 -0.03194192  0.0684182\n",
      "  -0.0724719  -0.07254965  0.15543678 -0.02318069 -0.07321054  0.14430411\n",
      "  -0.10908601 -0.18382685  0.13859995 -0.04522337 -0.15675503  0.21388506\n",
      "   0.0165647  -0.17840895  0.13319972 -0.10144511 -0.28827602  0.11187094\n",
      "  -0.04037448 -0.27505818  0.15627438  0.02773978 -0.27810818  0.10595472\n",
      "  -0.03495658 -0.30493968  0.13932092]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "all_values = normalize([r], axis=1)\n",
    "print(all_values)\n",
    "\n",
    "# Load PCA model and transform input\n",
    "pca = joblib.load('pca-model.pkl')\n",
    "principal_components = pca.transform(all_values)\n",
    "#print(principal_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model\n",
    "Using SVM model trained on bosphorus dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = joblib.load('svm-model.pkl')\n",
    "predicted_labels = svm.predict_proba(principal_components)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output\n",
    "We are sending 'output.json' file to Emotion Synthesis group which has the below printed format. The file contains the label and the percentage by which it predicts the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"ANGER\": 0.5621434189237174,\n",
      "   \"DISGUST\": 0.16585436907814466,\n",
      "   \"FEAR\": 0.058895752494619404,\n",
      "   \"HAPPY\": 0.0014569470031272024,\n",
      "   \"SADNESS\": 0.16397763216461944,\n",
      "   \"SURPRISE\": 0.04767188033577185\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Assign each score to its label\n",
    "confidence = {}\n",
    "labels = get_all_emotions()\n",
    "for index,emotion in enumerate(labels):\n",
    "    confidence[emotion] = predicted_labels[index]\n",
    "\n",
    "json_string = json.dumps(confidence,indent=3)\n",
    "with open('output.json', 'w') as outfile:\n",
    "    json.dump(confidence, outfile,indent=3)\n",
    "\n",
    "print(json_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
