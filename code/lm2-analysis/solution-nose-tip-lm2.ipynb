{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of features: 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Outer left eyebrow-x</th>\n",
       "      <th>Outer left eyebrow-y</th>\n",
       "      <th>Middle left eyebrow-x</th>\n",
       "      <th>Middle left eyebrow-y</th>\n",
       "      <th>Inner left eyebrow-x</th>\n",
       "      <th>Inner left eyebrow-y</th>\n",
       "      <th>Inner right eyebrow-x</th>\n",
       "      <th>Inner right eyebrow-y</th>\n",
       "      <th>Middle right eyebrow-x</th>\n",
       "      <th>...</th>\n",
       "      <th>Lower lip inner middle-x</th>\n",
       "      <th>Lower lip inner middle-y</th>\n",
       "      <th>Lower lip outer middle-x</th>\n",
       "      <th>Lower lip outer middle-y</th>\n",
       "      <th>Chin middle-x</th>\n",
       "      <th>Chin middle-y</th>\n",
       "      <th>Left ear lobe-x</th>\n",
       "      <th>Left ear lobe-y</th>\n",
       "      <th>Right ear lobe-x</th>\n",
       "      <th>Right ear lobe-y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAPPY</td>\n",
       "      <td>79.4496</td>\n",
       "      <td>557.174</td>\n",
       "      <td>176.086</td>\n",
       "      <td>436.378</td>\n",
       "      <td>433.784</td>\n",
       "      <td>444.431</td>\n",
       "      <td>675.375</td>\n",
       "      <td>452.484</td>\n",
       "      <td>908.914</td>\n",
       "      <td>...</td>\n",
       "      <td>546.527</td>\n",
       "      <td>1161.15</td>\n",
       "      <td>554.580</td>\n",
       "      <td>1225.58</td>\n",
       "      <td>570.686</td>\n",
       "      <td>1499.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANGER</td>\n",
       "      <td>90.6538</td>\n",
       "      <td>530.365</td>\n",
       "      <td>209.062</td>\n",
       "      <td>467.214</td>\n",
       "      <td>465.614</td>\n",
       "      <td>518.524</td>\n",
       "      <td>678.749</td>\n",
       "      <td>502.736</td>\n",
       "      <td>883.991</td>\n",
       "      <td>...</td>\n",
       "      <td>603.953</td>\n",
       "      <td>1118.97</td>\n",
       "      <td>595.863</td>\n",
       "      <td>1130.30</td>\n",
       "      <td>590.090</td>\n",
       "      <td>1467.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SURPRISE</td>\n",
       "      <td>86.5398</td>\n",
       "      <td>546.773</td>\n",
       "      <td>117.065</td>\n",
       "      <td>398.508</td>\n",
       "      <td>378.710</td>\n",
       "      <td>415.951</td>\n",
       "      <td>710.126</td>\n",
       "      <td>398.508</td>\n",
       "      <td>915.081</td>\n",
       "      <td>...</td>\n",
       "      <td>544.418</td>\n",
       "      <td>1261.94</td>\n",
       "      <td>535.696</td>\n",
       "      <td>1331.71</td>\n",
       "      <td>548.779</td>\n",
       "      <td>1567.19</td>\n",
       "      <td>36.7298</td>\n",
       "      <td>978.497</td>\n",
       "      <td>1078.27</td>\n",
       "      <td>947.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FEAR</td>\n",
       "      <td>104.6750</td>\n",
       "      <td>518.635</td>\n",
       "      <td>179.731</td>\n",
       "      <td>439.410</td>\n",
       "      <td>384.049</td>\n",
       "      <td>435.240</td>\n",
       "      <td>680.102</td>\n",
       "      <td>443.580</td>\n",
       "      <td>851.062</td>\n",
       "      <td>...</td>\n",
       "      <td>555.009</td>\n",
       "      <td>1223.32</td>\n",
       "      <td>563.349</td>\n",
       "      <td>1335.91</td>\n",
       "      <td>571.688</td>\n",
       "      <td>1552.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DISGUST</td>\n",
       "      <td>115.4420</td>\n",
       "      <td>526.418</td>\n",
       "      <td>241.744</td>\n",
       "      <td>459.320</td>\n",
       "      <td>435.145</td>\n",
       "      <td>514.577</td>\n",
       "      <td>648.280</td>\n",
       "      <td>490.895</td>\n",
       "      <td>845.627</td>\n",
       "      <td>...</td>\n",
       "      <td>585.227</td>\n",
       "      <td>1116.66</td>\n",
       "      <td>589.076</td>\n",
       "      <td>1150.04</td>\n",
       "      <td>596.969</td>\n",
       "      <td>1438.16</td>\n",
       "      <td>74.5932</td>\n",
       "      <td>913.326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  Outer left eyebrow-x  Outer left eyebrow-y  \\\n",
       "0     HAPPY               79.4496               557.174   \n",
       "1     ANGER               90.6538               530.365   \n",
       "2  SURPRISE               86.5398               546.773   \n",
       "3      FEAR              104.6750               518.635   \n",
       "4   DISGUST              115.4420               526.418   \n",
       "\n",
       "   Middle left eyebrow-x  Middle left eyebrow-y  Inner left eyebrow-x  \\\n",
       "0                176.086                436.378               433.784   \n",
       "1                209.062                467.214               465.614   \n",
       "2                117.065                398.508               378.710   \n",
       "3                179.731                439.410               384.049   \n",
       "4                241.744                459.320               435.145   \n",
       "\n",
       "   Inner left eyebrow-y  Inner right eyebrow-x  Inner right eyebrow-y  \\\n",
       "0               444.431                675.375                452.484   \n",
       "1               518.524                678.749                502.736   \n",
       "2               415.951                710.126                398.508   \n",
       "3               435.240                680.102                443.580   \n",
       "4               514.577                648.280                490.895   \n",
       "\n",
       "   Middle right eyebrow-x        ...         Lower lip inner middle-x  \\\n",
       "0                 908.914        ...                          546.527   \n",
       "1                 883.991        ...                          603.953   \n",
       "2                 915.081        ...                          544.418   \n",
       "3                 851.062        ...                          555.009   \n",
       "4                 845.627        ...                          585.227   \n",
       "\n",
       "   Lower lip inner middle-y  Lower lip outer middle-x  \\\n",
       "0                   1161.15                   554.580   \n",
       "1                   1118.97                   595.863   \n",
       "2                   1261.94                   535.696   \n",
       "3                   1223.32                   563.349   \n",
       "4                   1116.66                   589.076   \n",
       "\n",
       "   Lower lip outer middle-y  Chin middle-x  Chin middle-y  Left ear lobe-x  \\\n",
       "0                   1225.58        570.686        1499.38              NaN   \n",
       "1                   1130.30        590.090        1467.86              NaN   \n",
       "2                   1331.71        548.779        1567.19          36.7298   \n",
       "3                   1335.91        571.688        1552.74              NaN   \n",
       "4                   1150.04        596.969        1438.16          74.5932   \n",
       "\n",
       "   Left ear lobe-y  Right ear lobe-x  Right ear lobe-y  \n",
       "0              NaN               NaN               NaN  \n",
       "1              NaN               NaN               NaN  \n",
       "2          978.497           1078.27           947.863  \n",
       "3              NaN               NaN               NaN  \n",
       "4          913.326               NaN               NaN  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load original dataset\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '../../data/lm2.csv'\n",
    "data_df = pd.read_csv(file_path)\n",
    "print('Num of features: %s' % len(data_df.columns.values))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove NaN and Drop Static Landmarks\n",
    "These features are not important for identifying emotions. They can act as anchors which are static to other landmarks, in our case we use the nose tip (we normalize this distance later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of features:\t53\n",
      "after drop un-used\t35\n",
      "after drop NaN\t\t35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Outer left eyebrow-x</th>\n",
       "      <th>Outer left eyebrow-y</th>\n",
       "      <th>Middle left eyebrow-x</th>\n",
       "      <th>Middle left eyebrow-y</th>\n",
       "      <th>Inner left eyebrow-x</th>\n",
       "      <th>Inner left eyebrow-y</th>\n",
       "      <th>Inner right eyebrow-x</th>\n",
       "      <th>Inner right eyebrow-y</th>\n",
       "      <th>Middle right eyebrow-x</th>\n",
       "      <th>...</th>\n",
       "      <th>Upper lip outer middle-x</th>\n",
       "      <th>Upper lip outer middle-y</th>\n",
       "      <th>Right mouth corner-x</th>\n",
       "      <th>Right mouth corner-y</th>\n",
       "      <th>Upper lip inner middle-x</th>\n",
       "      <th>Upper lip inner middle-y</th>\n",
       "      <th>Lower lip inner middle-x</th>\n",
       "      <th>Lower lip inner middle-y</th>\n",
       "      <th>Lower lip outer middle-x</th>\n",
       "      <th>Lower lip outer middle-y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAPPY</td>\n",
       "      <td>79.4496</td>\n",
       "      <td>557.174</td>\n",
       "      <td>176.086</td>\n",
       "      <td>436.378</td>\n",
       "      <td>433.784</td>\n",
       "      <td>444.431</td>\n",
       "      <td>675.375</td>\n",
       "      <td>452.484</td>\n",
       "      <td>908.914</td>\n",
       "      <td>...</td>\n",
       "      <td>558.606</td>\n",
       "      <td>1072.57</td>\n",
       "      <td>796.171</td>\n",
       "      <td>1072.57</td>\n",
       "      <td>550.553</td>\n",
       "      <td>1104.78</td>\n",
       "      <td>546.527</td>\n",
       "      <td>1161.15</td>\n",
       "      <td>554.580</td>\n",
       "      <td>1225.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANGER</td>\n",
       "      <td>90.6538</td>\n",
       "      <td>530.365</td>\n",
       "      <td>209.062</td>\n",
       "      <td>467.214</td>\n",
       "      <td>465.614</td>\n",
       "      <td>518.524</td>\n",
       "      <td>678.749</td>\n",
       "      <td>502.736</td>\n",
       "      <td>883.991</td>\n",
       "      <td>...</td>\n",
       "      <td>599.810</td>\n",
       "      <td>1086.88</td>\n",
       "      <td>816.893</td>\n",
       "      <td>1110.57</td>\n",
       "      <td>599.810</td>\n",
       "      <td>1110.57</td>\n",
       "      <td>603.953</td>\n",
       "      <td>1118.97</td>\n",
       "      <td>595.863</td>\n",
       "      <td>1130.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SURPRISE</td>\n",
       "      <td>86.5398</td>\n",
       "      <td>546.773</td>\n",
       "      <td>117.065</td>\n",
       "      <td>398.508</td>\n",
       "      <td>378.710</td>\n",
       "      <td>415.951</td>\n",
       "      <td>710.126</td>\n",
       "      <td>398.508</td>\n",
       "      <td>915.081</td>\n",
       "      <td>...</td>\n",
       "      <td>531.336</td>\n",
       "      <td>1113.67</td>\n",
       "      <td>714.487</td>\n",
       "      <td>1187.80</td>\n",
       "      <td>540.057</td>\n",
       "      <td>1148.56</td>\n",
       "      <td>544.418</td>\n",
       "      <td>1261.94</td>\n",
       "      <td>535.696</td>\n",
       "      <td>1331.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FEAR</td>\n",
       "      <td>104.6750</td>\n",
       "      <td>518.635</td>\n",
       "      <td>179.731</td>\n",
       "      <td>439.410</td>\n",
       "      <td>384.049</td>\n",
       "      <td>435.240</td>\n",
       "      <td>680.102</td>\n",
       "      <td>443.580</td>\n",
       "      <td>851.062</td>\n",
       "      <td>...</td>\n",
       "      <td>559.179</td>\n",
       "      <td>1044.03</td>\n",
       "      <td>763.497</td>\n",
       "      <td>1085.72</td>\n",
       "      <td>563.349</td>\n",
       "      <td>1077.38</td>\n",
       "      <td>555.009</td>\n",
       "      <td>1223.32</td>\n",
       "      <td>563.349</td>\n",
       "      <td>1335.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DISGUST</td>\n",
       "      <td>115.4420</td>\n",
       "      <td>526.418</td>\n",
       "      <td>241.744</td>\n",
       "      <td>459.320</td>\n",
       "      <td>435.145</td>\n",
       "      <td>514.577</td>\n",
       "      <td>648.280</td>\n",
       "      <td>490.895</td>\n",
       "      <td>845.627</td>\n",
       "      <td>...</td>\n",
       "      <td>593.023</td>\n",
       "      <td>1051.36</td>\n",
       "      <td>837.733</td>\n",
       "      <td>1094.78</td>\n",
       "      <td>596.969</td>\n",
       "      <td>1098.73</td>\n",
       "      <td>585.227</td>\n",
       "      <td>1116.66</td>\n",
       "      <td>589.076</td>\n",
       "      <td>1150.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  Outer left eyebrow-x  Outer left eyebrow-y  \\\n",
       "0     HAPPY               79.4496               557.174   \n",
       "1     ANGER               90.6538               530.365   \n",
       "2  SURPRISE               86.5398               546.773   \n",
       "3      FEAR              104.6750               518.635   \n",
       "4   DISGUST              115.4420               526.418   \n",
       "\n",
       "   Middle left eyebrow-x  Middle left eyebrow-y  Inner left eyebrow-x  \\\n",
       "0                176.086                436.378               433.784   \n",
       "1                209.062                467.214               465.614   \n",
       "2                117.065                398.508               378.710   \n",
       "3                179.731                439.410               384.049   \n",
       "4                241.744                459.320               435.145   \n",
       "\n",
       "   Inner left eyebrow-y  Inner right eyebrow-x  Inner right eyebrow-y  \\\n",
       "0               444.431                675.375                452.484   \n",
       "1               518.524                678.749                502.736   \n",
       "2               415.951                710.126                398.508   \n",
       "3               435.240                680.102                443.580   \n",
       "4               514.577                648.280                490.895   \n",
       "\n",
       "   Middle right eyebrow-x            ...             Upper lip outer middle-x  \\\n",
       "0                 908.914            ...                              558.606   \n",
       "1                 883.991            ...                              599.810   \n",
       "2                 915.081            ...                              531.336   \n",
       "3                 851.062            ...                              559.179   \n",
       "4                 845.627            ...                              593.023   \n",
       "\n",
       "   Upper lip outer middle-y  Right mouth corner-x  Right mouth corner-y  \\\n",
       "0                   1072.57               796.171               1072.57   \n",
       "1                   1086.88               816.893               1110.57   \n",
       "2                   1113.67               714.487               1187.80   \n",
       "3                   1044.03               763.497               1085.72   \n",
       "4                   1051.36               837.733               1094.78   \n",
       "\n",
       "   Upper lip inner middle-x  Upper lip inner middle-y  \\\n",
       "0                   550.553                   1104.78   \n",
       "1                   599.810                   1110.57   \n",
       "2                   540.057                   1148.56   \n",
       "3                   563.349                   1077.38   \n",
       "4                   596.969                   1098.73   \n",
       "\n",
       "   Lower lip inner middle-x  Lower lip inner middle-y  \\\n",
       "0                   546.527                   1161.15   \n",
       "1                   603.953                   1118.97   \n",
       "2                   544.418                   1261.94   \n",
       "3                   555.009                   1223.32   \n",
       "4                   585.227                   1116.66   \n",
       "\n",
       "   Lower lip outer middle-x  Lower lip outer middle-y  \n",
       "0                   554.580                   1225.58  \n",
       "1                   595.863                   1130.30  \n",
       "2                   535.696                   1331.71  \n",
       "3                   563.349                   1335.91  \n",
       "4                   589.076                   1150.04  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def variety(lbl):\n",
    "    return [lbl+'-x', lbl+'-y']\n",
    "\n",
    "print('Num of features:\\t%s' % len(data_df.columns.values))\n",
    "\n",
    "# Drop features potentiall unuseful features \n",
    "drops = variety('Right nose peak')  + variety('Left nose peak')    + \\\n",
    "        variety('Left temple')      + variety('Right temple')      + \\\n",
    "        variety('Right ear lobe')   + variety('Left ear lobe')     + \\\n",
    "        variety('Nose saddle left') + variety('Nose saddle right') + \\\n",
    "        variety('Chin middle')\n",
    "        \n",
    "# errors = 'ignore' because it will throw if columns aren't there\n",
    "data_df = data_df.drop(drops, axis=1, errors='ignore')\n",
    "print('after drop un-used\\t%s' % len(data_df.columns.values))\n",
    "\n",
    "# Drop features where 'NaN' is present\n",
    "data_df = data_df.dropna(axis=1, how='any')\n",
    "print('after drop NaN\\t\\t%s' % len(data_df.columns.values))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the distance from all points to the nose tip (intuition: nose tip position is likely to be similar regardless of emotion)\n",
    "import math\n",
    "\n",
    "def get_euclidean_distance(x1, x2, y1, y2):\n",
    "    '''\n",
    "    Return the euclidean distance between two points\n",
    "    '''\n",
    "    term_1 = x1 - x2\n",
    "    term_2 = y1 - y2\n",
    "    return math.sqrt(term_1 ** 2 + term_2 ** 2 )\n",
    "\n",
    "def get_manhattan_distance(x1, x2, y1, y2):\n",
    "    '''\n",
    "    Return the manhattan distance between two points\n",
    "    '''\n",
    "    term_1 = math.fabs(x1 - x2)\n",
    "    term_2 = math.fabs(y1 - y2)\n",
    "    return term_1 + term_2\n",
    "\n",
    "# Create new dataset using distance from each landmark to the nose tip as features\n",
    "all_landmarks = ['Outer left eyebrow', 'Middle left eyebrow', 'Inner left eyebrow', 'Inner right eyebrow', 'Middle right eyebrow', 'Outer right eyebrow', 'Left temple', 'Outer left eye corner', 'Inner left eye corner', 'Inner right eye corner', 'Outer right eye corner', 'Right temple', 'Nose saddle left', 'Nose saddle right', 'Left nose peak', 'Right nose peak', 'Left mouth corner', 'Upper lip outer middle', 'Right mouth corner', 'Upper lip inner middle', 'Lower lip inner middle', 'Lower lip outer middle', 'Chin middle', 'Left ear lobe', 'Right ear lobe']\n",
    "valid_landmarks = []\n",
    "\n",
    "# Remove landmarks which were previously removed due to undefined values ('NaN')\n",
    "columns = data_df.columns.values\n",
    "for landmark in all_landmarks:\n",
    "    if landmark + '-x' in columns and  landmark + '-y' in columns:\n",
    "        valid_landmarks.append(landmark)\n",
    "        \n",
    "# Create dictionary to temporarily hold distance values\n",
    "d = {}\n",
    "for landmark in valid_landmarks:\n",
    "    d[landmark + '-distance'] = []\n",
    "    \n",
    "# For each feature, compute distance from nose tip\n",
    "for _, row in data_df.iterrows():\n",
    "    for landmark in valid_landmarks:\n",
    "        nose_x, nose_y = (row['Nose tip-x'], row['Nose tip-y'])\n",
    "        landmark_x, landmark_y = (row[landmark + '-x'], row[landmark + '-y'])\n",
    "        distance = get_euclidean_distance(landmark_x, nose_x, landmark_y, nose_y)\n",
    "        d[landmark + '-distance'].append(distance)\n",
    "        \n",
    "# Remove the nose-tip?\n",
    "# data_df = data_df.drop(['Nose tip-x', 'Nose tip-y'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance to Nose Tip \n",
    "Intuition: nose tip position is likely to be similar regardless of emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Inner left eye corner-distance</th>\n",
       "      <th>Inner left eyebrow-distance</th>\n",
       "      <th>Inner right eye corner-distance</th>\n",
       "      <th>Inner right eyebrow-distance</th>\n",
       "      <th>Left mouth corner-distance</th>\n",
       "      <th>Lower lip inner middle-distance</th>\n",
       "      <th>Lower lip outer middle-distance</th>\n",
       "      <th>Middle left eyebrow-distance</th>\n",
       "      <th>Middle right eyebrow-distance</th>\n",
       "      <th>Outer left eye corner-distance</th>\n",
       "      <th>Outer left eyebrow-distance</th>\n",
       "      <th>Outer right eye corner-distance</th>\n",
       "      <th>Outer right eyebrow-distance</th>\n",
       "      <th>Right mouth corner-distance</th>\n",
       "      <th>Upper lip inner middle-distance</th>\n",
       "      <th>Upper lip outer middle-distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAPPY</td>\n",
       "      <td>297.831252</td>\n",
       "      <td>455.150020</td>\n",
       "      <td>298.851438</td>\n",
       "      <td>450.063255</td>\n",
       "      <td>323.435445</td>\n",
       "      <td>276.559753</td>\n",
       "      <td>341.009790</td>\n",
       "      <td>583.438327</td>\n",
       "      <td>568.227334</td>\n",
       "      <td>467.936613</td>\n",
       "      <td>572.910552</td>\n",
       "      <td>471.069484</td>\n",
       "      <td>566.272147</td>\n",
       "      <td>310.067169</td>\n",
       "      <td>220.175190</td>\n",
       "      <td>188.180022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANGER</td>\n",
       "      <td>339.238567</td>\n",
       "      <td>381.048521</td>\n",
       "      <td>317.530065</td>\n",
       "      <td>386.245112</td>\n",
       "      <td>310.725384</td>\n",
       "      <td>240.701545</td>\n",
       "      <td>251.698214</td>\n",
       "      <td>560.782249</td>\n",
       "      <td>508.857336</td>\n",
       "      <td>496.060458</td>\n",
       "      <td>608.893667</td>\n",
       "      <td>471.410580</td>\n",
       "      <td>566.459261</td>\n",
       "      <td>324.373455</td>\n",
       "      <td>232.105614</td>\n",
       "      <td>208.438757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SURPRISE</td>\n",
       "      <td>310.840237</td>\n",
       "      <td>498.995762</td>\n",
       "      <td>327.111617</td>\n",
       "      <td>520.263588</td>\n",
       "      <td>343.942428</td>\n",
       "      <td>372.863253</td>\n",
       "      <td>442.563158</td>\n",
       "      <td>645.863384</td>\n",
       "      <td>636.777941</td>\n",
       "      <td>460.359724</td>\n",
       "      <td>565.867471</td>\n",
       "      <td>471.624484</td>\n",
       "      <td>616.776342</td>\n",
       "      <td>347.370657</td>\n",
       "      <td>259.428104</td>\n",
       "      <td>224.594412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FEAR</td>\n",
       "      <td>325.703578</td>\n",
       "      <td>458.191004</td>\n",
       "      <td>324.707988</td>\n",
       "      <td>438.606055</td>\n",
       "      <td>319.023552</td>\n",
       "      <td>360.966256</td>\n",
       "      <td>473.712145</td>\n",
       "      <td>562.032930</td>\n",
       "      <td>543.325541</td>\n",
       "      <td>492.100778</td>\n",
       "      <td>562.427710</td>\n",
       "      <td>482.531825</td>\n",
       "      <td>584.070368</td>\n",
       "      <td>309.083194</td>\n",
       "      <td>215.414073</td>\n",
       "      <td>181.879798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DISGUST</td>\n",
       "      <td>330.512636</td>\n",
       "      <td>373.931348</td>\n",
       "      <td>328.746551</td>\n",
       "      <td>386.481891</td>\n",
       "      <td>319.889063</td>\n",
       "      <td>250.835962</td>\n",
       "      <td>284.434519</td>\n",
       "      <td>517.168617</td>\n",
       "      <td>537.457441</td>\n",
       "      <td>455.743065</td>\n",
       "      <td>559.944867</td>\n",
       "      <td>493.541260</td>\n",
       "      <td>578.315301</td>\n",
       "      <td>359.265905</td>\n",
       "      <td>234.576694</td>\n",
       "      <td>187.214468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  Inner left eye corner-distance  Inner left eyebrow-distance  \\\n",
       "0     HAPPY                      297.831252                   455.150020   \n",
       "1     ANGER                      339.238567                   381.048521   \n",
       "2  SURPRISE                      310.840237                   498.995762   \n",
       "3      FEAR                      325.703578                   458.191004   \n",
       "4   DISGUST                      330.512636                   373.931348   \n",
       "\n",
       "   Inner right eye corner-distance  Inner right eyebrow-distance  \\\n",
       "0                       298.851438                    450.063255   \n",
       "1                       317.530065                    386.245112   \n",
       "2                       327.111617                    520.263588   \n",
       "3                       324.707988                    438.606055   \n",
       "4                       328.746551                    386.481891   \n",
       "\n",
       "   Left mouth corner-distance  Lower lip inner middle-distance  \\\n",
       "0                  323.435445                       276.559753   \n",
       "1                  310.725384                       240.701545   \n",
       "2                  343.942428                       372.863253   \n",
       "3                  319.023552                       360.966256   \n",
       "4                  319.889063                       250.835962   \n",
       "\n",
       "   Lower lip outer middle-distance  Middle left eyebrow-distance  \\\n",
       "0                       341.009790                    583.438327   \n",
       "1                       251.698214                    560.782249   \n",
       "2                       442.563158                    645.863384   \n",
       "3                       473.712145                    562.032930   \n",
       "4                       284.434519                    517.168617   \n",
       "\n",
       "   Middle right eyebrow-distance  Outer left eye corner-distance  \\\n",
       "0                     568.227334                      467.936613   \n",
       "1                     508.857336                      496.060458   \n",
       "2                     636.777941                      460.359724   \n",
       "3                     543.325541                      492.100778   \n",
       "4                     537.457441                      455.743065   \n",
       "\n",
       "   Outer left eyebrow-distance  Outer right eye corner-distance  \\\n",
       "0                   572.910552                       471.069484   \n",
       "1                   608.893667                       471.410580   \n",
       "2                   565.867471                       471.624484   \n",
       "3                   562.427710                       482.531825   \n",
       "4                   559.944867                       493.541260   \n",
       "\n",
       "   Outer right eyebrow-distance  Right mouth corner-distance  \\\n",
       "0                    566.272147                   310.067169   \n",
       "1                    566.459261                   324.373455   \n",
       "2                    616.776342                   347.370657   \n",
       "3                    584.070368                   309.083194   \n",
       "4                    578.315301                   359.265905   \n",
       "\n",
       "   Upper lip inner middle-distance  Upper lip outer middle-distance  \n",
       "0                       220.175190                       188.180022  \n",
       "1                       232.105614                       208.438757  \n",
       "2                       259.428104                       224.594412  \n",
       "3                       215.414073                       181.879798  \n",
       "4                       234.576694                       187.214468  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataframe (with distance from each feature to nose tip)\n",
    "new_df = pd.concat([data_df[['Label']], pd.DataFrame.from_dict(d)], axis = 1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization and Dimensionality Reduction\n",
    "Normalize values after computing their distance to a static point (nose tip for now). Then, we run these points through PCA and tSNE methods. \n",
    "\n",
    "tSNE performs better so we move forward with that dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x != 'Label' for x in new_df.columns.values]\n",
    "\n",
    "# Separating out the features\n",
    "values = new_df.loc[:, features].values\n",
    "\n",
    "# Separating out the label\n",
    "labels = new_df.loc[:,['Label']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale values (mean = 0 and variance = 1)\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "values = normalize(values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of columns we want to reduce\n",
    "num_of_columns = 14\n",
    "column_names = ['Col %s' % (i + 1) for i in range(num_of_columns)]                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Col 1</th>\n",
       "      <th>Col 2</th>\n",
       "      <th>Col 3</th>\n",
       "      <th>Col 4</th>\n",
       "      <th>Col 5</th>\n",
       "      <th>Col 6</th>\n",
       "      <th>Col 7</th>\n",
       "      <th>Col 8</th>\n",
       "      <th>Col 9</th>\n",
       "      <th>Col 10</th>\n",
       "      <th>Col 11</th>\n",
       "      <th>Col 12</th>\n",
       "      <th>Col 13</th>\n",
       "      <th>Col 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAPPY</td>\n",
       "      <td>-0.488233</td>\n",
       "      <td>0.164605</td>\n",
       "      <td>0.084666</td>\n",
       "      <td>-1.244050</td>\n",
       "      <td>-0.696989</td>\n",
       "      <td>-0.641906</td>\n",
       "      <td>0.350272</td>\n",
       "      <td>-0.554375</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.114033</td>\n",
       "      <td>-1.675602</td>\n",
       "      <td>0.106994</td>\n",
       "      <td>-0.728105</td>\n",
       "      <td>0.533165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANGER</td>\n",
       "      <td>-0.709971</td>\n",
       "      <td>-0.308697</td>\n",
       "      <td>-1.424850</td>\n",
       "      <td>0.557993</td>\n",
       "      <td>1.083411</td>\n",
       "      <td>0.333080</td>\n",
       "      <td>0.112275</td>\n",
       "      <td>-1.526441</td>\n",
       "      <td>-1.217706</td>\n",
       "      <td>-1.098153</td>\n",
       "      <td>1.443898</td>\n",
       "      <td>0.423606</td>\n",
       "      <td>2.084312</td>\n",
       "      <td>1.402473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SURPRISE</td>\n",
       "      <td>0.281406</td>\n",
       "      <td>1.572144</td>\n",
       "      <td>0.413689</td>\n",
       "      <td>-1.145305</td>\n",
       "      <td>-2.179174</td>\n",
       "      <td>-1.299749</td>\n",
       "      <td>-0.273081</td>\n",
       "      <td>-1.081012</td>\n",
       "      <td>-0.057646</td>\n",
       "      <td>0.798109</td>\n",
       "      <td>0.216582</td>\n",
       "      <td>-0.362036</td>\n",
       "      <td>0.129865</td>\n",
       "      <td>1.531268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FEAR</td>\n",
       "      <td>-0.047833</td>\n",
       "      <td>0.784718</td>\n",
       "      <td>1.580889</td>\n",
       "      <td>1.037307</td>\n",
       "      <td>-0.335277</td>\n",
       "      <td>-1.182441</td>\n",
       "      <td>-1.309762</td>\n",
       "      <td>0.553971</td>\n",
       "      <td>0.248721</td>\n",
       "      <td>-1.302502</td>\n",
       "      <td>-1.681033</td>\n",
       "      <td>0.405270</td>\n",
       "      <td>-2.695630</td>\n",
       "      <td>-0.564704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DISGUST</td>\n",
       "      <td>-0.589718</td>\n",
       "      <td>-0.364557</td>\n",
       "      <td>-0.881238</td>\n",
       "      <td>0.864712</td>\n",
       "      <td>-0.241180</td>\n",
       "      <td>1.936002</td>\n",
       "      <td>-0.677493</td>\n",
       "      <td>-1.333136</td>\n",
       "      <td>1.020877</td>\n",
       "      <td>-0.373555</td>\n",
       "      <td>1.260352</td>\n",
       "      <td>-0.101358</td>\n",
       "      <td>2.080482</td>\n",
       "      <td>-0.792858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label     Col 1     Col 2     Col 3     Col 4     Col 5     Col 6  \\\n",
       "0     HAPPY -0.488233  0.164605  0.084666 -1.244050 -0.696989 -0.641906   \n",
       "1     ANGER -0.709971 -0.308697 -1.424850  0.557993  1.083411  0.333080   \n",
       "2  SURPRISE  0.281406  1.572144  0.413689 -1.145305 -2.179174 -1.299749   \n",
       "3      FEAR -0.047833  0.784718  1.580889  1.037307 -0.335277 -1.182441   \n",
       "4   DISGUST -0.589718 -0.364557 -0.881238  0.864712 -0.241180  1.936002   \n",
       "\n",
       "      Col 7     Col 8     Col 9    Col 10    Col 11    Col 12    Col 13  \\\n",
       "0  0.350272 -0.554375 -0.282240 -0.114033 -1.675602  0.106994 -0.728105   \n",
       "1  0.112275 -1.526441 -1.217706 -1.098153  1.443898  0.423606  2.084312   \n",
       "2 -0.273081 -1.081012 -0.057646  0.798109  0.216582 -0.362036  0.129865   \n",
       "3 -1.309762  0.553971  0.248721 -1.302502 -1.681033  0.405270 -2.695630   \n",
       "4 -0.677493 -1.333136  1.020877 -0.373555  1.260352 -0.101358  2.080482   \n",
       "\n",
       "     Col 14  \n",
       "0  0.533165  \n",
       "1  1.402473  \n",
       "2  1.531268  \n",
       "3 -0.564704  \n",
       "4 -0.792858  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Use PCA to reduce dimensionality\n",
    "pca = PCA(n_components=num_of_columns, whiten = True)\n",
    "principal_components = pca.fit_transform(values)\n",
    "principal_df = pd.DataFrame(data = principal_components, columns = column_names)\n",
    "\n",
    "# Add the label to the dataframe with the principal components\n",
    "principal_labels_df = pd.concat([new_df[['Label']], principal_df], axis = 1)\n",
    "principal_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the PCA 2d projection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel(column_names[0], fontsize = 12)\n",
    "ax.set_ylabel(column_names[1], fontsize = 12)\n",
    "ax.set_title('2 component PCA', fontsize = 15)\n",
    "\n",
    "targets = ['ANGER', 'DISGUST', 'FEAR', 'HAPPY', 'SADNESS', 'SURPRISE']\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y']\n",
    "for target, color in zip(targets, colors):\n",
    "    indexes_to_keep = principal_labels_df['Label'] == target\n",
    "    ax.scatter(\n",
    "        principal_labels_df.loc[indexes_to_keep, column_names[0]],\n",
    "        principal_labels_df.loc[indexes_to_keep, column_names[1]],\n",
    "        c = color,\n",
    "        s = 50\n",
    "    )\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Col 1</th>\n",
       "      <th>Col 2</th>\n",
       "      <th>Col 3</th>\n",
       "      <th>Col 4</th>\n",
       "      <th>Col 5</th>\n",
       "      <th>Col 6</th>\n",
       "      <th>Col 7</th>\n",
       "      <th>Col 8</th>\n",
       "      <th>Col 9</th>\n",
       "      <th>Col 10</th>\n",
       "      <th>Col 11</th>\n",
       "      <th>Col 12</th>\n",
       "      <th>Col 13</th>\n",
       "      <th>Col 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAPPY</td>\n",
       "      <td>1.276243</td>\n",
       "      <td>2.352659</td>\n",
       "      <td>8.970236</td>\n",
       "      <td>1.885012</td>\n",
       "      <td>-5.724248</td>\n",
       "      <td>6.177265</td>\n",
       "      <td>0.729555</td>\n",
       "      <td>-9.022329</td>\n",
       "      <td>2.220377</td>\n",
       "      <td>-9.503185</td>\n",
       "      <td>-36.892036</td>\n",
       "      <td>9.225079</td>\n",
       "      <td>4.371387</td>\n",
       "      <td>0.912996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANGER</td>\n",
       "      <td>-0.912880</td>\n",
       "      <td>3.890665</td>\n",
       "      <td>1.015965</td>\n",
       "      <td>-4.020353</td>\n",
       "      <td>0.317116</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.498462</td>\n",
       "      <td>6.209013</td>\n",
       "      <td>-0.115560</td>\n",
       "      <td>0.757458</td>\n",
       "      <td>1.078042</td>\n",
       "      <td>0.472054</td>\n",
       "      <td>2.196428</td>\n",
       "      <td>0.171616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SURPRISE</td>\n",
       "      <td>-2.531759</td>\n",
       "      <td>1.300422</td>\n",
       "      <td>-0.678265</td>\n",
       "      <td>1.451538</td>\n",
       "      <td>4.258102</td>\n",
       "      <td>2.015879</td>\n",
       "      <td>0.118300</td>\n",
       "      <td>-0.278212</td>\n",
       "      <td>1.753649</td>\n",
       "      <td>-4.289062</td>\n",
       "      <td>4.018318</td>\n",
       "      <td>0.772790</td>\n",
       "      <td>6.386789</td>\n",
       "      <td>3.802541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FEAR</td>\n",
       "      <td>0.899223</td>\n",
       "      <td>3.607758</td>\n",
       "      <td>-0.075574</td>\n",
       "      <td>-0.341002</td>\n",
       "      <td>1.464211</td>\n",
       "      <td>2.085397</td>\n",
       "      <td>-0.651102</td>\n",
       "      <td>-2.293162</td>\n",
       "      <td>-0.195711</td>\n",
       "      <td>-1.357057</td>\n",
       "      <td>1.908325</td>\n",
       "      <td>8.567263</td>\n",
       "      <td>0.776971</td>\n",
       "      <td>0.297038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DISGUST</td>\n",
       "      <td>-2.883043</td>\n",
       "      <td>3.865585</td>\n",
       "      <td>0.715038</td>\n",
       "      <td>0.624818</td>\n",
       "      <td>-0.281825</td>\n",
       "      <td>-1.538340</td>\n",
       "      <td>0.429596</td>\n",
       "      <td>3.846588</td>\n",
       "      <td>0.319313</td>\n",
       "      <td>0.913550</td>\n",
       "      <td>-4.729297</td>\n",
       "      <td>-0.324951</td>\n",
       "      <td>-0.112044</td>\n",
       "      <td>3.285027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label     Col 1     Col 2     Col 3     Col 4     Col 5     Col 6  \\\n",
       "0     HAPPY  1.276243  2.352659  8.970236  1.885012 -5.724248  6.177265   \n",
       "1     ANGER -0.912880  3.890665  1.015965 -4.020353  0.317116  0.209877   \n",
       "2  SURPRISE -2.531759  1.300422 -0.678265  1.451538  4.258102  2.015879   \n",
       "3      FEAR  0.899223  3.607758 -0.075574 -0.341002  1.464211  2.085397   \n",
       "4   DISGUST -2.883043  3.865585  0.715038  0.624818 -0.281825 -1.538340   \n",
       "\n",
       "      Col 7     Col 8     Col 9    Col 10     Col 11    Col 12    Col 13  \\\n",
       "0  0.729555 -9.022329  2.220377 -9.503185 -36.892036  9.225079  4.371387   \n",
       "1  0.498462  6.209013 -0.115560  0.757458   1.078042  0.472054  2.196428   \n",
       "2  0.118300 -0.278212  1.753649 -4.289062   4.018318  0.772790  6.386789   \n",
       "3 -0.651102 -2.293162 -0.195711 -1.357057   1.908325  8.567263  0.776971   \n",
       "4  0.429596  3.846588  0.319313  0.913550  -4.729297 -0.324951 -0.112044   \n",
       "\n",
       "     Col 14  \n",
       "0  0.912996  \n",
       "1  0.171616  \n",
       "2  3.802541  \n",
       "3  0.297038  \n",
       "4  3.285027  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "# Use tSNE to reduce dimensionality\n",
    "tsne = manifold.TSNE(n_components=num_of_columns, init='pca', random_state=0, method='exact')\n",
    "tsne_components = tsne.fit_transform(values)\n",
    "tsne_df = pd.DataFrame(data = tsne_components, columns = column_names)\n",
    "\n",
    "# Add the label to the dataframe with the tSNE components\n",
    "tsne_labels_df = pd.concat([new_df[['Label']], tsne_df], axis = 1)\n",
    "tsne_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110b21a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the tSNE 2d projection\n",
    "plt.scatter(tsne_components[:,0], tsne_components[:,1], c=colors, s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Dataset Labels Distribution--------------------\n",
      "          Col 1  Col 2  Col 3  Col 4  Col 5  Col 6  Col 7  Col 8  Col 9  \\\n",
      "Label                                                                     \n",
      "ANGER        71     71     71     71     71     71     71     71     71   \n",
      "DISGUST      69     69     69     69     69     69     69     69     69   \n",
      "FEAR         70     70     70     70     70     70     70     70     70   \n",
      "HAPPY       106    106    106    106    106    106    106    106    106   \n",
      "SADNESS      66     66     66     66     66     66     66     66     66   \n",
      "SURPRISE     71     71     71     71     71     71     71     71     71   \n",
      "\n",
      "          Col 10  Col 11  Col 12  Col 13  Col 14  \n",
      "Label                                             \n",
      "ANGER         71      71      71      71      71  \n",
      "DISGUST       69      69      69      69      69  \n",
      "FEAR          70      70      70      70      70  \n",
      "HAPPY        106     106     106     106     106  \n",
      "SADNESS       66      66      66      66      66  \n",
      "SURPRISE      71      71      71      71      71  \n",
      "Total number of inputs: 453\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the labels distribution\n",
    "print('--------------------Dataset Labels Distribution--------------------')\n",
    "rows, cols = tsne_labels_df.shape\n",
    "print(tsne_labels_df.groupby('Label').count())\n",
    "print('Total number of inputs: %s' % rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for classification\n",
    "Balance classes for training from dimensionality reduction process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifications\n",
    "Two simple unsupervised methods: KNN and SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Training--------------------\n",
      "          Col 1  Col 2  Col 3  Col 4  Col 5  Col 6  Col 7  Col 8  Col 9  \\\n",
      "Label                                                                     \n",
      "ANGER        63     63     63     63     63     63     63     63     63   \n",
      "DISGUST      63     63     63     63     63     63     63     63     63   \n",
      "FEAR         63     63     63     63     63     63     63     63     63   \n",
      "HAPPY        63     63     63     63     63     63     63     63     63   \n",
      "SADNESS      63     63     63     63     63     63     63     63     63   \n",
      "SURPRISE     63     63     63     63     63     63     63     63     63   \n",
      "\n",
      "          Col 10  Col 11  Col 12  Col 13  Col 14  \n",
      "Label                                             \n",
      "ANGER         63      63      63      63      63  \n",
      "DISGUST       63      63      63      63      63  \n",
      "FEAR          63      63      63      63      63  \n",
      "HAPPY         63      63      63      63      63  \n",
      "SADNESS       63      63      63      63      63  \n",
      "SURPRISE      63      63      63      63      63  \n",
      "Total number of inputs: 378\n",
      "--------------------Testing--------------------\n",
      "          Col 1  Col 2  Col 3  Col 4  Col 5  Col 6  Col 7  Col 8  Col 9  \\\n",
      "Label                                                                     \n",
      "ANGER         8      8      8      8      8      8      8      8      8   \n",
      "DISGUST       6      6      6      6      6      6      6      6      6   \n",
      "FEAR          7      7      7      7      7      7      7      7      7   \n",
      "HAPPY        43     43     43     43     43     43     43     43     43   \n",
      "SADNESS       3      3      3      3      3      3      3      3      3   \n",
      "SURPRISE      8      8      8      8      8      8      8      8      8   \n",
      "\n",
      "          Col 10  Col 11  Col 12  Col 13  Col 14  \n",
      "Label                                             \n",
      "ANGER          8       8       8       8       8  \n",
      "DISGUST        6       6       6       6       6  \n",
      "FEAR           7       7       7       7       7  \n",
      "HAPPY         43      43      43      43      43  \n",
      "SADNESS        3       3       3       3       3  \n",
      "SURPRISE       8       8       8       8       8  \n",
      "Total number of inputs: 75\n",
      "--------------------Result--------------------\n",
      "kNN classifier accuracy: 0.49%\n",
      "SVM classifier accuracy: 0.66%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def get_train_test_split(df):\n",
    "    '''\n",
    "    Split data into training and test sets\n",
    "    '''\n",
    "    # Shuffle data frame\n",
    "    df = df.sample(frac=1)\n",
    "    # Select same num per class, remaining go to test set\n",
    "    num_of_inputs = 63\n",
    "    cols = ['Label'] + column_names\n",
    "    train_df, test_df = (pd.DataFrame(columns=cols), pd.DataFrame(columns=cols))\n",
    "    for x in targets:\n",
    "        train_df = train_df.append(df.loc[df['Label'] == x][0:num_of_inputs], ignore_index=True)\n",
    "        test_df = test_df.append(df.loc[df['Label'] == x][num_of_inputs:], ignore_index=True)\n",
    "\n",
    "    # Shuffle data frames\n",
    "    train_df = train_df.sample(frac=1)\n",
    "    test_df = test_df.sample(frac=1)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "runs = 100\n",
    "knn_scores = []\n",
    "svm_scores = []\n",
    "for index in range(runs):\n",
    "    train_df, test_df = get_train_test_split(principal_labels_df)\n",
    "\n",
    "    # Split train and test labels/data\n",
    "    train_data   = train_df.iloc[:,1:].values\n",
    "    train_labels = train_df.iloc[:,:1].values.ravel()\n",
    "\n",
    "    test_data   = test_df.iloc[:,1:].values\n",
    "    test_labels = test_df.iloc[:,:1].values.ravel()\n",
    "    \n",
    "    # Just print once\n",
    "    if index == 0:\n",
    "        # Take a look at the labels distribution\n",
    "        print('--------------------Training--------------------')\n",
    "        rows, cols = train_df.shape\n",
    "        print(train_df.groupby('Label').count())\n",
    "        print('Total number of inputs: %s' % rows)\n",
    "\n",
    "        print('--------------------Testing--------------------')\n",
    "        rows, cols = test_df.shape\n",
    "        print(test_df.groupby('Label').count())\n",
    "        print('Total number of inputs: %s' % rows)\n",
    "        \n",
    "    # Classifications\n",
    "\n",
    "    # Use KNN to predict\n",
    "    kNNClassifier = neighbors.KNeighborsClassifier(n_neighbors=10).fit(train_data, train_labels)\n",
    "    predicted_labels = kNNClassifier.predict(test_data)\n",
    "    acc_knn = accuracy_score(test_labels, predicted_labels)\n",
    "    knn_scores.append(acc_knn)\n",
    "\n",
    "    # Use SVM to predict\n",
    "    clf_svm = LinearSVC()\n",
    "    clf_svm.fit(train_data, train_labels)\n",
    "    predicted_labels = clf_svm.predict(test_data)\n",
    "    acc_svm = accuracy_score(test_labels, predicted_labels)\n",
    "    svm_scores.append(acc_svm)\n",
    " \n",
    "print('--------------------Result--------------------')\n",
    "print(\"kNN classifier accuracy: %.02f%%\" % (sum(knn_scores) / runs))      \n",
    "print(\"SVM classifier accuracy: %.02f%%\" % (sum(svm_scores) / runs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
